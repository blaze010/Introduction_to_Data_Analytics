{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5ea95e4",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a684a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import xgboost\n",
    "import lightgbm\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5762b5",
   "metadata": {},
   "source": [
    "### Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7e989be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('TrainingData.csv', index_col = 'application_key',low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8283a17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'application_key': ['Application ID (primary key)'],\n",
       " 'mvar1': [\"Credit worthiness score calculated on the basis of borrower's credit history\"],\n",
       " 'mvar2': ['A score calculated based on the number and riskiness of credit enquiries made to any lender by a borrower'],\n",
       " 'mvar3': ['Severity of default by the borrower on any loan(s). Severity is a function of amount, time since default and number of defaults'],\n",
       " 'mvar4': ['Severity of default by the borrower on auto loan(s). Severity is a function of amount, time since default and number of defaults'],\n",
       " 'mvar5': ['Severity of default by the borrower on education loan(s). Severity is a function of amount, time since default and number of defaults'],\n",
       " 'mvar6': ['Minimum of credit available on all revolving credit cards (in $)'],\n",
       " 'mvar7': ['Maximum of credit available on all active credit lines (in $)'],\n",
       " 'mvar8': ['Maximum of credit available on all active revolving credit cards (in $)'],\n",
       " 'mvar9': ['Sum of available credit on credit cards that the borrower has missed 1 payment (in $)'],\n",
       " 'mvar10': ['Total amount of credit available on accepted credit lines (in $)'],\n",
       " 'mvar11': ['Amount of dues collected post default where due amount was more than 500 (in $)'],\n",
       " 'mvar12': ['Sum of amount due on active credit cards (in $)'],\n",
       " 'mvar13': ['Annual amount paid towards all credit cards during the previous year (in $)'],\n",
       " 'mvar14': ['Annual income (in $)'],\n",
       " 'mvar15': ['Estimated market value of a properety owned/used by the borrower (in $)'],\n",
       " 'mvar16': ['Number of active revolving credit cards on which full credit limit is utilized by the borrower'],\n",
       " 'mvar17': ['Number of active credit cards on which full credit limit is utilized by the borrower'],\n",
       " 'mvar18': ['Number of active credit lines on which full credit limit is utilized by the borrower'],\n",
       " 'mvar19': ['Number of active credit cards on which atleast 75% credit limit is utilized by the borrower'],\n",
       " 'mvar20': ['Number of active credit lines on which atleast 75% credit limit is utilized by the borrower'],\n",
       " 'mvar21': ['Average utilization of active revolving credit card loans (%)'],\n",
       " 'mvar22': ['Average utilization of line on all active credit lines activated in last 2 years (%)'],\n",
       " 'mvar23': ['Average utilization of line on all active credit cards activated in last 1 year (%)'],\n",
       " 'mvar24': ['Average utilization of line on credit cards on which the borrower has missed 1 payment during last 6 months (%)'],\n",
       " 'mvar25': ['Average tenure of active revolving credit cards (in days)'],\n",
       " 'mvar26': ['Tenure of oldest credit card among all active credit cards (in days)'],\n",
       " 'mvar27': ['Tenure of oldest revolving credit card among all active revolving credit cards (in days)'],\n",
       " 'mvar28': ['Number of days since last missed payment on any credit line'],\n",
       " 'mvar29': ['Tenure of oldest credit line (in days)'],\n",
       " 'mvar30': ['Maximum tenure on all auto loans (in days)'],\n",
       " 'mvar31': ['Maximum tenure on all education loans (in days)'],\n",
       " 'mvar32': ['Sum of tenures (in months) of active credit cards'],\n",
       " 'mvar33': ['Duration of stay at the current residential address (in years)'],\n",
       " 'mvar34': ['Number of active credit lines over the last 6 months on which the borrower has missed 1 payment'],\n",
       " 'mvar35': ['Number of revolving credit cards over the last 2 years on which the borrower has missed 1 payment'],\n",
       " 'mvar36': ['Number of active credit lines'],\n",
       " 'mvar37': ['Number of credit cards with an active tenure of at least 2 years'],\n",
       " 'mvar38': ['Number of credit lines activated in last 2 years'],\n",
       " 'mvar39': ['Number of credit lines on which the borrower has current delinquency'],\n",
       " 'mvar40': ['Utilization of line on active education loans (%)'],\n",
       " 'mvar41': ['Utilization of line on active auto loans (%)'],\n",
       " 'mvar42': ['Financial stress index of the borrower. This index is a function of collection trades, bankruptcies files, tax liens invoked, etc. '],\n",
       " 'mvar43': ['Number of credit lines on which the borrower has never missed a payment in last 2 yrs, yet considered as high risk loans based on market prediction of economic scenario'],\n",
       " 'mvar44': ['Ratio of maximum amount due on all active credit lines and sum of amounts due on all active credit lines '],\n",
       " 'mvar45': ['Number of mortgage loans on which the borrower has missed 2 payments'],\n",
       " 'mvar46': ['Number of auto loans on which the borrower has missed 2 payments'],\n",
       " 'mvar47': ['Type of product that the applicant applied for. (C = Charge; L = Lending)'],\n",
       " 'mvar48': ['Integer value assigned to an application basis a predefined function'],\n",
       " 'mvar49': ['Bucketized credit worthiness score for the applicant'],\n",
       " 'mvar50': ['Compound feature created as a product of bucketized credit worthiness and mvar48'],\n",
       " 'default_ind': ['Indicator for default']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = pd.read_csv('Data_Dictionary.csv')\n",
    "label_dict = label_dict.set_index('Name').T.to_dict('list')\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08b96362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mvar1</th>\n",
       "      <th>mvar2</th>\n",
       "      <th>mvar3</th>\n",
       "      <th>mvar4</th>\n",
       "      <th>mvar5</th>\n",
       "      <th>mvar6</th>\n",
       "      <th>mvar7</th>\n",
       "      <th>mvar8</th>\n",
       "      <th>mvar9</th>\n",
       "      <th>mvar10</th>\n",
       "      <th>...</th>\n",
       "      <th>mvar43</th>\n",
       "      <th>mvar44</th>\n",
       "      <th>mvar45</th>\n",
       "      <th>mvar46</th>\n",
       "      <th>mvar47</th>\n",
       "      <th>mvar48</th>\n",
       "      <th>mvar49</th>\n",
       "      <th>mvar50</th>\n",
       "      <th>mvar51</th>\n",
       "      <th>default_ind</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230032</th>\n",
       "      <td>1696</td>\n",
       "      <td>1.6541</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6015</td>\n",
       "      <td>322</td>\n",
       "      <td>40369</td>\n",
       "      <td>18414</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.63899</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "      <td>770</td>\n",
       "      <td>4</td>\n",
       "      <td>3080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230033</th>\n",
       "      <td>1846</td>\n",
       "      <td>0.8095</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102</td>\n",
       "      <td>7532</td>\n",
       "      <td>3171</td>\n",
       "      <td>18234</td>\n",
       "      <td>13664</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.63836</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>L</td>\n",
       "      <td>732</td>\n",
       "      <td>437</td>\n",
       "      <td>5</td>\n",
       "      <td>2185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230034</th>\n",
       "      <td>1745</td>\n",
       "      <td>0.4001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>2536</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>2536</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>89</td>\n",
       "      <td>795</td>\n",
       "      <td>4</td>\n",
       "      <td>3180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230035</th>\n",
       "      <td>1739</td>\n",
       "      <td>0.2193</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1982</td>\n",
       "      <td>26440</td>\n",
       "      <td>4955</td>\n",
       "      <td>20316</td>\n",
       "      <td>37013</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.53241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>755</td>\n",
       "      <td>4</td>\n",
       "      <td>3020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230036</th>\n",
       "      <td>1787</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5451</td>\n",
       "      <td>5494</td>\n",
       "      <td>5494</td>\n",
       "      <td>7987</td>\n",
       "      <td>4696</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92665</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>L</td>\n",
       "      <td>5</td>\n",
       "      <td>425</td>\n",
       "      <td>4</td>\n",
       "      <td>1700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                mvar1   mvar2  mvar3  mvar4  mvar5    mvar6  mvar7    mvar8  \\\n",
       "application_key                                                               \n",
       "230032           1696  1.6541  0.000    0.0    0.0        0   6015      322   \n",
       "230033           1846  0.8095  0.000    0.0    0.0      102   7532     3171   \n",
       "230034           1745  0.4001  0.000    0.0    0.0  missing   2536  missing   \n",
       "230035           1739  0.2193  0.000    0.0    0.0     1982  26440     4955   \n",
       "230036           1787  0.0118  0.225    0.0    0.0     5451   5494     5494   \n",
       "\n",
       "                   mvar9 mvar10  ... mvar43   mvar44 mvar45  mvar46 mvar47  \\\n",
       "application_key                  ...                                         \n",
       "230032             40369  18414  ...     10  0.63899     na       0      C   \n",
       "230033             18234  13664  ...     13  0.63836     na      na      L   \n",
       "230034           missing   2536  ...      1  1.00000     na       0      C   \n",
       "230035             20316  37013  ...      3  0.53241      0       0      L   \n",
       "230036              7987   4696  ...      1  0.92665     na      na      L   \n",
       "\n",
       "                mvar48 mvar49 mvar50 mvar51 default_ind  \n",
       "application_key                                          \n",
       "230032              10    770      4   3080           0  \n",
       "230033             732    437      5   2185           1  \n",
       "230034              89    795      4   3180           1  \n",
       "230035               3    755      4   3020           0  \n",
       "230036               5    425      4   1700           0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20b8d563",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 83000 entries, 230032 to 578068\n",
      "Data columns (total 52 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   mvar1        83000 non-null  object \n",
      " 1   mvar2        77114 non-null  float64\n",
      " 2   mvar3        82465 non-null  float64\n",
      " 3   mvar4        82465 non-null  float64\n",
      " 4   mvar5        82465 non-null  float64\n",
      " 5   mvar6        83000 non-null  object \n",
      " 6   mvar7        83000 non-null  object \n",
      " 7   mvar8        83000 non-null  object \n",
      " 8   mvar9        83000 non-null  object \n",
      " 9   mvar10       83000 non-null  object \n",
      " 10  mvar11       83000 non-null  object \n",
      " 11  mvar12       83000 non-null  object \n",
      " 12  mvar13       83000 non-null  object \n",
      " 13  mvar14       83000 non-null  int64  \n",
      " 14  mvar15       83000 non-null  object \n",
      " 15  mvar16       83000 non-null  object \n",
      " 16  mvar17       83000 non-null  object \n",
      " 17  mvar18       83000 non-null  object \n",
      " 18  mvar19       83000 non-null  object \n",
      " 19  mvar20       83000 non-null  object \n",
      " 20  mvar21       59538 non-null  float64\n",
      " 21  mvar22       52332 non-null  float64\n",
      " 22  mvar23       40689 non-null  float64\n",
      " 23  mvar24       63470 non-null  float64\n",
      " 24  mvar25       83000 non-null  object \n",
      " 25  mvar26       83000 non-null  object \n",
      " 26  mvar27       83000 non-null  object \n",
      " 27  mvar28       83000 non-null  object \n",
      " 28  mvar29       83000 non-null  object \n",
      " 29  mvar30       83000 non-null  object \n",
      " 30  mvar31       83000 non-null  object \n",
      " 31  mvar32       83000 non-null  object \n",
      " 32  mvar33       81131 non-null  float64\n",
      " 33  mvar34       83000 non-null  object \n",
      " 34  mvar35       83000 non-null  object \n",
      " 35  mvar36       83000 non-null  object \n",
      " 36  mvar37       83000 non-null  object \n",
      " 37  mvar38       83000 non-null  object \n",
      " 38  mvar39       83000 non-null  object \n",
      " 39  mvar40       83000 non-null  object \n",
      " 40  mvar41       83000 non-null  object \n",
      " 41  mvar42       83000 non-null  object \n",
      " 42  mvar43       83000 non-null  object \n",
      " 43  mvar44       74851 non-null  float64\n",
      " 44  mvar45       83000 non-null  object \n",
      " 45  mvar46       83000 non-null  object \n",
      " 46  mvar47       83000 non-null  object \n",
      " 47  mvar48       83000 non-null  int64  \n",
      " 48  mvar49       83000 non-null  int64  \n",
      " 49  mvar50       83000 non-null  object \n",
      " 50  mvar51       83000 non-null  object \n",
      " 51  default_ind  83000 non-null  int64  \n",
      "dtypes: float64(10), int64(4), object(38)\n",
      "memory usage: 33.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80de0ff",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b4899c",
   "metadata": {},
   "source": [
    "Function for extracting non-numeric elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f29fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_numeric(elements):\n",
    "    non_numerics = []\n",
    "    for el in elements:\n",
    "        try:\n",
    "            el = float(el)\n",
    "        except:\n",
    "            non_numerics.append(el)\n",
    "    \n",
    "    return non_numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d73a7992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['na']\n",
      "1 []\n",
      "2 []\n",
      "3 []\n",
      "4 []\n",
      "5 ['missing']\n",
      "6 ['missing']\n",
      "7 ['missing']\n",
      "8 ['missing']\n",
      "9 ['missing']\n",
      "10 ['missing']\n",
      "11 ['missing']\n",
      "12 ['missing']\n",
      "13 []\n",
      "14 ['missing']\n",
      "15 ['na']\n",
      "16 ['na']\n",
      "17 ['na']\n",
      "18 ['na']\n",
      "19 ['na']\n",
      "20 []\n",
      "21 []\n",
      "22 []\n",
      "23 []\n",
      "24 ['missing']\n",
      "25 ['missing']\n",
      "26 ['missing']\n",
      "27 ['missing']\n",
      "28 ['missing']\n",
      "29 ['missing']\n",
      "30 ['missing']\n",
      "31 ['missing']\n",
      "32 []\n",
      "33 ['na']\n",
      "34 ['na']\n",
      "35 ['na']\n",
      "36 ['na']\n",
      "37 ['na']\n",
      "38 ['na']\n",
      "39 ['missing']\n",
      "40 ['missing']\n",
      "41 ['missing']\n",
      "42 ['na']\n",
      "43 []\n",
      "44 ['na']\n",
      "45 ['na']\n",
      "46 ['C', 'L']\n",
      "47 []\n",
      "48 []\n",
      "49 ['#VALUE!']\n",
      "50 ['#VALUE!']\n"
     ]
    }
   ],
   "source": [
    "for i in range(51):\n",
    "    lol =get_non_numeric(list(df_train.iloc[:, i].unique()))\n",
    "    print(i, lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78d16642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n",
      "1 []\n",
      "2 []\n",
      "3 []\n",
      "4 []\n",
      "5 []\n",
      "6 []\n",
      "7 []\n",
      "8 []\n",
      "9 []\n",
      "10 []\n",
      "11 []\n",
      "12 []\n",
      "13 []\n",
      "14 []\n",
      "15 []\n",
      "16 []\n",
      "17 []\n",
      "18 []\n",
      "19 []\n",
      "20 []\n",
      "21 []\n",
      "22 []\n",
      "23 []\n",
      "24 []\n",
      "25 []\n",
      "26 []\n",
      "27 []\n",
      "28 []\n",
      "29 []\n",
      "30 []\n",
      "31 []\n",
      "32 []\n",
      "33 []\n",
      "34 []\n",
      "35 []\n",
      "36 []\n",
      "37 []\n",
      "38 []\n",
      "39 []\n",
      "40 []\n",
      "41 []\n",
      "42 []\n",
      "43 []\n",
      "44 []\n",
      "45 []\n",
      "46 ['C', 'L']\n",
      "47 []\n",
      "48 []\n",
      "49 []\n",
      "50 []\n"
     ]
    }
   ],
   "source": [
    "for i in range(51):\n",
    "    lol = ['na', 'missing', '#VALUE!']\n",
    "    for el in lol:\n",
    "        df_train = df_train.replace(el, np.NaN)\n",
    "    lol = get_non_numeric(list(df_train.iloc[:, i].unique()))\n",
    "    print(i, lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2560e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n",
      "1 []\n",
      "2 []\n",
      "3 []\n",
      "4 []\n",
      "5 []\n",
      "6 []\n",
      "7 []\n",
      "8 []\n",
      "9 []\n",
      "10 []\n",
      "11 []\n",
      "12 []\n",
      "13 []\n",
      "14 []\n",
      "15 []\n",
      "16 []\n",
      "17 []\n",
      "18 []\n",
      "19 []\n",
      "20 []\n",
      "21 []\n",
      "22 []\n",
      "23 []\n",
      "24 []\n",
      "25 []\n",
      "26 []\n",
      "27 []\n",
      "28 []\n",
      "29 []\n",
      "30 []\n",
      "31 []\n",
      "32 []\n",
      "33 []\n",
      "34 []\n",
      "35 []\n",
      "36 []\n",
      "37 []\n",
      "38 []\n",
      "39 []\n",
      "40 []\n",
      "41 []\n",
      "42 []\n",
      "43 []\n",
      "44 []\n",
      "45 []\n",
      "46 []\n",
      "47 []\n",
      "48 []\n",
      "49 []\n",
      "50 []\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.get_dummies(df_train, columns = ['mvar47'], prefix = ['type'])\n",
    "for i in range(51):\n",
    "    lol =get_non_numeric(list(df_train.iloc[:, i].unique()))\n",
    "    print(i, lol)\n",
    "for el in list(df_train.columns):\n",
    "    df_train[el] = pd.to_numeric(df_train[el])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e6dcf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 83000 entries, 230032 to 578068\n",
      "Data columns (total 53 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   mvar1        79267 non-null  float64\n",
      " 1   mvar2        77114 non-null  float64\n",
      " 2   mvar3        82465 non-null  float64\n",
      " 3   mvar4        82465 non-null  float64\n",
      " 4   mvar5        82465 non-null  float64\n",
      " 5   mvar6        63299 non-null  float64\n",
      " 6   mvar7        75326 non-null  float64\n",
      " 7   mvar8        63291 non-null  float64\n",
      " 8   mvar9        71318 non-null  float64\n",
      " 9   mvar10       82465 non-null  float64\n",
      " 10  mvar11       36283 non-null  float64\n",
      " 11  mvar12       68422 non-null  float64\n",
      " 12  mvar13       73311 non-null  float64\n",
      " 13  mvar14       83000 non-null  int64  \n",
      " 14  mvar15       49481 non-null  float64\n",
      " 15  mvar16       63757 non-null  float64\n",
      " 16  mvar17       66501 non-null  float64\n",
      " 17  mvar18       67641 non-null  float64\n",
      " 18  mvar19       82995 non-null  float64\n",
      " 19  mvar20       82465 non-null  float64\n",
      " 20  mvar21       59538 non-null  float64\n",
      " 21  mvar22       52332 non-null  float64\n",
      " 22  mvar23       40689 non-null  float64\n",
      " 23  mvar24       63470 non-null  float64\n",
      " 24  mvar25       75138 non-null  float64\n",
      " 25  mvar26       72071 non-null  float64\n",
      " 26  mvar27       69350 non-null  float64\n",
      " 27  mvar28       82465 non-null  float64\n",
      " 28  mvar29       82465 non-null  float64\n",
      " 29  mvar30       45012 non-null  float64\n",
      " 30  mvar31       24461 non-null  float64\n",
      " 31  mvar32       75138 non-null  float64\n",
      " 32  mvar33       81131 non-null  float64\n",
      " 33  mvar34       82465 non-null  float64\n",
      " 34  mvar35       48132 non-null  float64\n",
      " 35  mvar36       79841 non-null  float64\n",
      " 36  mvar37       75138 non-null  float64\n",
      " 37  mvar38       82465 non-null  float64\n",
      " 38  mvar39       76671 non-null  float64\n",
      " 39  mvar40       17930 non-null  float64\n",
      " 40  mvar41       25736 non-null  float64\n",
      " 41  mvar42       80977 non-null  float64\n",
      " 42  mvar43       82111 non-null  float64\n",
      " 43  mvar44       74851 non-null  float64\n",
      " 44  mvar45       37080 non-null  float64\n",
      " 45  mvar46       59397 non-null  float64\n",
      " 46  mvar48       83000 non-null  int64  \n",
      " 47  mvar49       83000 non-null  int64  \n",
      " 48  mvar50       79267 non-null  float64\n",
      " 49  mvar51       79267 non-null  float64\n",
      " 50  default_ind  83000 non-null  int64  \n",
      " 51  type_C       83000 non-null  uint8  \n",
      " 52  type_L       83000 non-null  uint8  \n",
      "dtypes: float64(47), int64(4), uint8(2)\n",
      "memory usage: 33.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b65bf8",
   "metadata": {},
   "source": [
    "#### Simple imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58f39d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "mean_imputer.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80ca883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_imputed = mean_imputer.transform(df_train)\n",
    "df_train_imputed = pd.DataFrame(df_train_imputed, columns = df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f90ed9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83000 entries, 0 to 82999\n",
      "Data columns (total 51 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   mvar1        83000 non-null  float64\n",
      " 1   mvar2        83000 non-null  float64\n",
      " 2   mvar3        83000 non-null  float64\n",
      " 3   mvar4        83000 non-null  float64\n",
      " 4   mvar5        83000 non-null  float64\n",
      " 5   mvar6        83000 non-null  float64\n",
      " 6   mvar7        83000 non-null  float64\n",
      " 7   mvar8        83000 non-null  float64\n",
      " 8   mvar9        83000 non-null  float64\n",
      " 9   mvar10       83000 non-null  float64\n",
      " 10  mvar11       83000 non-null  float64\n",
      " 11  mvar12       83000 non-null  float64\n",
      " 12  mvar13       83000 non-null  float64\n",
      " 13  mvar14       83000 non-null  float64\n",
      " 14  mvar15       83000 non-null  float64\n",
      " 15  mvar16       83000 non-null  float64\n",
      " 16  mvar17       83000 non-null  float64\n",
      " 17  mvar18       83000 non-null  float64\n",
      " 18  mvar19       83000 non-null  float64\n",
      " 19  mvar20       83000 non-null  float64\n",
      " 20  mvar21       83000 non-null  float64\n",
      " 21  mvar22       83000 non-null  float64\n",
      " 22  mvar23       83000 non-null  float64\n",
      " 23  mvar24       83000 non-null  float64\n",
      " 24  mvar25       83000 non-null  float64\n",
      " 25  mvar26       83000 non-null  float64\n",
      " 26  mvar27       83000 non-null  float64\n",
      " 27  mvar28       83000 non-null  float64\n",
      " 28  mvar29       83000 non-null  float64\n",
      " 29  mvar30       83000 non-null  float64\n",
      " 30  mvar31       83000 non-null  float64\n",
      " 31  mvar32       83000 non-null  float64\n",
      " 32  mvar33       83000 non-null  float64\n",
      " 33  mvar34       83000 non-null  float64\n",
      " 34  mvar35       83000 non-null  float64\n",
      " 35  mvar36       83000 non-null  float64\n",
      " 36  mvar37       83000 non-null  float64\n",
      " 37  mvar38       83000 non-null  float64\n",
      " 38  mvar39       83000 non-null  float64\n",
      " 39  mvar40       83000 non-null  float64\n",
      " 40  mvar41       83000 non-null  float64\n",
      " 41  mvar42       83000 non-null  float64\n",
      " 42  mvar43       83000 non-null  float64\n",
      " 43  mvar44       83000 non-null  float64\n",
      " 44  mvar45       83000 non-null  float64\n",
      " 45  mvar46       83000 non-null  float64\n",
      " 46  mvar48       83000 non-null  float64\n",
      " 47  mvar49       83000 non-null  float64\n",
      " 48  mvar50       83000 non-null  float64\n",
      " 49  mvar51       83000 non-null  float64\n",
      " 50  default_ind  83000 non-null  float64\n",
      "dtypes: float64(51)\n",
      "memory usage: 32.3 MB\n"
     ]
    }
   ],
   "source": [
    "df_train_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b463f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_imputed['default_ind'] = df_train_imputed['default_ind'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f7150d",
   "metadata": {},
   "source": [
    "## Using KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb9a09b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNNImputer(weights='distance')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_imputer = KNNImputer(missing_values=np.nan, weights = 'distance')\n",
    "knn_imputer.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72cabc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_imputed = knn_imputer.transform(df_train)\n",
    "df_train_imputed = pd.DataFrame(df_train_imputed, columns = df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14800605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b3cdc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_imputed = df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e775bd29",
   "metadata": {},
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaa8b66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='default_ind', ylabel='count'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'default_ind', data = df_train_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf290cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28740963855421686"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_imputed['default_ind'].sum()/len(df_train_imputed['default_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82d7a43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.479354433032907"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight = len(df_train_imputed['default_ind'])/df_train_imputed['default_ind'].sum() - 1\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b52a3ff",
   "metadata": {},
   "source": [
    "Imbalanced dataset, though it is not that bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff072426",
   "metadata": {},
   "source": [
    "#### Todo: more visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2f86e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4ada93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89457560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16321cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18ac69ee",
   "metadata": {},
   "source": [
    "### Building models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f04c9c8",
   "metadata": {},
   "source": [
    "#### Test set generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "156af634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mvar1', 'mvar2', 'mvar3', 'mvar4', 'mvar5', 'mvar6', 'mvar7', 'mvar8', 'mvar9', 'mvar10', 'mvar11', 'mvar12', 'mvar13', 'mvar14', 'mvar15', 'mvar16', 'mvar17', 'mvar18', 'mvar19', 'mvar20', 'mvar21', 'mvar22', 'mvar23', 'mvar24', 'mvar25', 'mvar26', 'mvar27', 'mvar28', 'mvar29', 'mvar30', 'mvar31', 'mvar32', 'mvar33', 'mvar34', 'mvar35', 'mvar36', 'mvar37', 'mvar38', 'mvar39', 'mvar40', 'mvar41', 'mvar42', 'mvar43', 'mvar44', 'mvar45', 'mvar46', 'mvar48', 'mvar49', 'mvar50', 'mvar51', 'type_C', 'type_L']\n"
     ]
    }
   ],
   "source": [
    "x = list(df_train_imputed.columns)\n",
    "x.remove('default_ind')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "979fd7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_label_cols = list(df_train_imputed.columns)\n",
    "non_label_cols.remove('default_ind')\n",
    "\n",
    "\n",
    "X = df_train_imputed[non_label_cols]\n",
    "y = df_train_imputed['default_ind']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y,test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1698114a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2873895582329317"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b262ec44",
   "metadata": {},
   "source": [
    "## Using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b2470e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(learning_rate = 0.01,  \n",
    "                      colsample_bytree = 0.25,\n",
    "                      subsample = 0.5,\n",
    "                      objective = 'binary:logistic', \n",
    "                      n_estimators = 3000,\n",
    "                      max_depth = 14, \n",
    "                      scale_pos_weight = 5,\n",
    "                      reg_lambda = 8,\n",
    "                      gamma = 4,\n",
    "                      tree_method = 'gpu_hist')\n",
    "\n",
    "# colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=5, subsample=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a72cf831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.25,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=4, gpu_id=0,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.01, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=14, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=3000, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d170157a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92     35100\n",
      "           1       1.00      0.73      0.84     23000\n",
      "\n",
      "    accuracy                           0.89     58100\n",
      "   macro avg       0.92      0.86      0.88     58100\n",
      "weighted avg       0.91      0.89      0.89     58100\n",
      "\n",
      "0.8409279830726214\n"
     ]
    }
   ],
   "source": [
    "y_pred10 = xgb_model.predict(X_train)\n",
    "print(classification_report(y_pred10, y_train))\n",
    "print(f1_score(y_pred10, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5da0023e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.78     14660\n",
      "           1       0.72      0.51      0.60     10240\n",
      "\n",
      "    accuracy                           0.72     24900\n",
      "   macro avg       0.72      0.69      0.69     24900\n",
      "weighted avg       0.72      0.72      0.71     24900\n",
      "\n",
      "0.5959990802483329\n"
     ]
    }
   ],
   "source": [
    "y_pred11 = xgb_model.predict(X_test)\n",
    "print(classification_report(y_pred11, y_test))\n",
    "print(f1_score(y_pred11, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97fd7986",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = xgboost.plot_importance(xgb_model, max_num_features = 20, importance_type = 'weight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c5fd9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_importance = xgb_model.get_booster().get_score(importance_type='weight')\n",
    "importance_df = pd.DataFrame.from_dict(data=f_importance, orient='index')\n",
    "importance_df.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cf25a0",
   "metadata": {},
   "source": [
    "## Tuning XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a0fb8f",
   "metadata": {},
   "source": [
    "#### First we tune class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ae340f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Train: 0.9944137433925997 Test: 0.5196487937942205\n",
      "2 - Train: 0.9948739345532575 Test: 0.5594706877981227\n",
      "3 - Train: 0.9906858092074039 Test: 0.5702967444540479\n",
      "4 - Train: 0.9852498672488053 Test: 0.5785783033136257\n",
      "5 - Train: 0.9799595082303924 Test: 0.5826980444149817\n",
      "6 - Train: 0.9738729806963318 Test: 0.5849251419721218\n",
      "7 - Train: 0.967805500014489 Test: 0.5841989298079949\n"
     ]
    }
   ],
   "source": [
    "scale = list(range(1,8))\n",
    "f_scores = []\n",
    "\n",
    "for el in scale:\n",
    "    \n",
    "    tune_wt_xgb = XGBClassifier(learning_rate = 0.01,  \n",
    "                      colsample_bytree = 0.6,\n",
    "                      subsample = 0.8,\n",
    "                      objective = 'binary:logistic', \n",
    "                      n_estimators = 3000,\n",
    "                      max_depth = 10, \n",
    "                      scale_pos_weight = el,\n",
    "                      gamma = 0,\n",
    "                      verbosity = 2,\n",
    "                      tree_method = 'gpu_hist')\n",
    "    \n",
    "    tune_wt_xgb.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = tune_wt_xgb.predict(X_train)\n",
    "    y_test_pred = tune_wt_xgb.predict(X_test)\n",
    "    \n",
    "    train_f = f1_score(y_train, y_train_pred)\n",
    "    test_f = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    f_scores.append([el, train_f, test_f])\n",
    "    print(el,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061aa29d",
   "metadata": {},
   "source": [
    "#### Further tuning this parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ffa2cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5 - Train: 0.9827855104022599 Test: 0.5803360550644443\n",
      "4.75 - Train: 0.9813416389974438 Test: 0.582227583433856\n",
      "5.0 - Train: 0.9799595082303924 Test: 0.5826980444149817\n",
      "5.25 - Train: 0.9779795021961932 Test: 0.5848646512546928\n",
      "5.5 - Train: 0.9764926027717677 Test: 0.5835133896418516\n",
      "5.75 - Train: 0.9748679179193789 Test: 0.5876469442099109\n",
      "6.0 - Train: 0.9738729806963318 Test: 0.5849251419721218\n",
      "6.25 - Train: 0.9718891863578163 Test: 0.5824705806700533\n",
      "6.5 - Train: 0.9716064467329959 Test: 0.5841464192334672\n",
      "6.75 - Train: 0.9698008014402695 Test: 0.5846251186333439\n",
      "7.0 - Train: 0.967805500014489 Test: 0.5841989298079949\n",
      "7.25 - Train: 0.9654275307856853 Test: 0.5843708940749546\n",
      "7.5 - Train: 0.9654833487511563 Test: 0.5831466268359472\n"
     ]
    }
   ],
   "source": [
    "scale = [4.50, 4.75, 5.00, 5.25, 5.50, 5.75, 6.00, 6.25, 6.50, 6.75, 7.00, 7.25, 7.50]\n",
    "f_scores = []\n",
    "\n",
    "for el in scale:\n",
    "    \n",
    "    tune_wt_xgb = XGBClassifier(learning_rate = 0.01,  \n",
    "                      colsample_bytree = 0.6,\n",
    "                      subsample = 0.8,\n",
    "                      objective = 'binary:logistic', \n",
    "                      n_estimators = 3000,\n",
    "                      max_depth = 10, \n",
    "                      scale_pos_weight = el,\n",
    "                      gamma = 0,\n",
    "                      verbosity = 2,\n",
    "                      tree_method = 'gpu_hist')\n",
    "    \n",
    "    tune_wt_xgb.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = tune_wt_xgb.predict(X_train)\n",
    "    y_test_pred = tune_wt_xgb.predict(X_test)\n",
    "    \n",
    "    train_f = f1_score(y_train, y_train_pred)\n",
    "    test_f = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    f_scores.append([el, train_f, test_f])\n",
    "    print(el,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299e3e01",
   "metadata": {},
   "source": [
    "We select class_weight to be 6 (or 5) we'll see later.\n",
    "Edakk eppzheluokke aayt 5 also try cheyth nokkaa.\n",
    "Verthe oru rasam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d86d4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 - Train: 0.6423321598418875 Test: 0.5714830710538865\n",
      "6 - Train: 0.70200754190553 Test: 0.5787310814874211\n",
      "7 - Train: 0.7806168233127095 Test: 0.5840916390108125\n",
      "8 - Train: 0.8647092389894694 Test: 0.5884940386618822\n",
      "9 - Train: 0.9393564356435644 Test: 0.5881616818921287\n",
      "10 - Train: 0.9799595082303924 Test: 0.5826980444149817\n",
      "11 - Train: 0.9939585131394899 Test: 0.5740805359759927\n",
      "12 - Train: 0.9986245664394212 Test: 0.569020172910663\n",
      "13 - Train: 0.9999101823298704 Test: 0.5647752394988946\n",
      "14 - Train: 1.0 Test: 0.5628822915112635\n"
     ]
    }
   ],
   "source": [
    "deep = [5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "f_scores = []\n",
    "\n",
    "for el in deep:\n",
    "    \n",
    "    tune_dp_xgb = XGBClassifier(learning_rate = 0.01,  \n",
    "                              colsample_bytree = 0.6,\n",
    "                              subsample = 0.8,\n",
    "                              objective = 'binary:logistic', \n",
    "                              n_estimators = 3000,\n",
    "                              max_depth = el, \n",
    "                              scale_pos_weight = 5,\n",
    "                              gamma = 0,\n",
    "                              verbosity = 2,\n",
    "                              tree_method = 'gpu_hist')\n",
    "    \n",
    "    tune_dp_xgb.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = tune_dp_xgb.predict(X_train)\n",
    "    y_test_pred = tune_dp_xgb.predict(X_test)\n",
    "    \n",
    "    train_f = f1_score(y_train, y_train_pred)\n",
    "    test_f = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    f_scores.append([el, train_f, test_f])\n",
    "    print(el,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85217e4",
   "metadata": {},
   "source": [
    "Values 8 and 9 are pretty good estimates for the max_depth. Extended search from 7 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f26be52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************\n",
      "Depth:  7\n",
      "***************************\n",
      "1 - Train: 0.779224455137277 Test: 0.5846400856301847\n",
      "2 - Train: 0.7797706140557888 Test: 0.5833467202141901\n",
      "3 - Train: 0.7772154878192302 Test: 0.5839431654291971\n",
      "4 - Train: 0.7631713080950836 Test: 0.5833113977362464\n",
      "5 - Train: 0.7395531837916064 Test: 0.5801510917934389\n",
      "6 - Train: 0.7160526548281652 Test: 0.5787553213054937\n",
      "***************************\n",
      "Depth:  8\n",
      "***************************\n",
      "1 - Train: 0.864067603297216 Test: 0.5871315225574795\n",
      "2 - Train: 0.8613048194638152 Test: 0.5889620136242927\n",
      "3 - Train: 0.8445999036828631 Test: 0.5870295507601206\n",
      "4 - Train: 0.8127889625480076 Test: 0.5855190654617589\n",
      "5 - Train: 0.7815809379727685 Test: 0.5826754739272865\n",
      "6 - Train: 0.7503200438917338 Test: 0.5828935681070068\n",
      "***************************\n",
      "Depth:  9\n",
      "***************************\n",
      "1 - Train: 0.939171517759217 Test: 0.5863423760523854\n",
      "2 - Train: 0.9278728606356969 Test: 0.5869043959422072\n",
      "3 - Train: 0.8899021411620404 Test: 0.5896022289406605\n",
      "4 - Train: 0.847946669380693 Test: 0.5895815542271563\n",
      "5 - Train: 0.8099685434904532 Test: 0.5864645132937816\n",
      "6 - Train: 0.7793469291524224 Test: 0.5868237814675951\n",
      "***************************\n",
      "Depth:  10\n",
      "***************************\n",
      "1 - Train: 0.978609939052977 Test: 0.58386819294647\n",
      "2 - Train: 0.9570175941314689 Test: 0.5851606323304437\n",
      "3 - Train: 0.9134978388138097 Test: 0.5872361077408397\n",
      "4 - Train: 0.8696694818058596 Test: 0.5909222990643342\n",
      "5 - Train: 0.8331790779698327 Test: 0.5891150342966378\n",
      "6 - Train: 0.802300016911889 Test: 0.5868125854993159\n"
     ]
    }
   ],
   "source": [
    "deep = [7, 8, 9, 10]\n",
    "gams = [1, 2, 3, 4, 5, 6]\n",
    "f_scores = []\n",
    "\n",
    "for el1 in deep:\n",
    "    print('***************************')\n",
    "    print('Depth: ',el1)\n",
    "    print('***************************')\n",
    "    for el2 in gams:\n",
    "\n",
    "        tune_dp_xgb = XGBClassifier(learning_rate = 0.01,  \n",
    "                              colsample_bytree = 0.6,\n",
    "                              subsample = 0.8,\n",
    "                              objective = 'binary:logistic', \n",
    "                              n_estimators = 3000,\n",
    "                              max_depth = el1, \n",
    "                              scale_pos_weight = 5,\n",
    "                              gamma = el2,\n",
    "                              verbosity = 2,\n",
    "                              tree_method = 'gpu_hist')\n",
    "\n",
    "        tune_dp_xgb.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = tune_dp_xgb.predict(X_train)\n",
    "        y_test_pred = tune_dp_xgb.predict(X_test)\n",
    "\n",
    "        train_f = f1_score(y_train, y_train_pred)\n",
    "        test_f = f1_score(y_test, y_test_pred)\n",
    "\n",
    "        f_scores.append([el, train_f, test_f])\n",
    "        print( el2,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91ba98f",
   "metadata": {},
   "source": [
    "Range of gammas between 3 to 5 works best. The value of max_depth can be on higher side. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cd2054",
   "metadata": {},
   "source": [
    "Further tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c778fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************\n",
      "Depth:  9\n",
      "***************************\n",
      "3 - Train: 0.8899021411620404 Test: 0.5896022289406605\n",
      "3.25 - Train: 0.8779075886748764 Test: 0.5891463772367264\n",
      "3.5 - Train: 0.86781848459617 Test: 0.5892857142857143\n",
      "3.75 - Train: 0.8575763810307582 Test: 0.589453102536086\n",
      "4 - Train: 0.847946669380693 Test: 0.5895815542271563\n",
      "4.25 - Train: 0.8375694496819771 Test: 0.5879501775348025\n",
      "4.5 - Train: 0.8293302770580027 Test: 0.5864981262934169\n",
      "4.75 - Train: 0.818752616157388 Test: 0.588267877915028\n",
      "5 - Train: 0.8099685434904532 Test: 0.5864645132937816\n",
      "5.25 - Train: 0.8014102192601178 Test: 0.5873536812164971\n",
      "5.5 - Train: 0.794223307946544 Test: 0.5875914386345163\n",
      "5.75 - Train: 0.7872765310003804 Test: 0.5862180524102233\n",
      "6 - Train: 0.7793469291524224 Test: 0.5868237814675951\n",
      "***************************\n",
      "Depth:  10\n",
      "***************************\n",
      "3 - Train: 0.9134978388138097 Test: 0.5872361077408397\n",
      "3.25 - Train: 0.9036431548746819 Test: 0.5892814227349195\n",
      "3.5 - Train: 0.8926441883472819 Test: 0.5890402808353662\n",
      "3.75 - Train: 0.8814177054722164 Test: 0.5891618666980134\n",
      "4 - Train: 0.8696694818058596 Test: 0.5909222990643342\n",
      "4.25 - Train: 0.861222276729235 Test: 0.5916955017301038\n",
      "4.5 - Train: 0.8506773477562058 Test: 0.5881346263548204\n",
      "4.75 - Train: 0.841315929002449 Test: 0.588574987261507\n",
      "5 - Train: 0.8331790779698327 Test: 0.5891150342966378\n",
      "5.25 - Train: 0.8254401190181007 Test: 0.5887281461207619\n",
      "5.5 - Train: 0.8173554125104419 Test: 0.5883656509695291\n",
      "5.75 - Train: 0.80885037606796 Test: 0.5878664539904296\n",
      "6 - Train: 0.802300016911889 Test: 0.5868125854993159\n",
      "***************************\n",
      "Depth:  11\n",
      "***************************\n",
      "3 - Train: 0.9291417443316178 Test: 0.587057296495457\n",
      "3.25 - Train: 0.9178759894459103 Test: 0.5881778808027817\n",
      "3.5 - Train: 0.9074355908250896 Test: 0.5902015204537228\n",
      "3.75 - Train: 0.8969482054588437 Test: 0.5901032650868502\n",
      "4 - Train: 0.8867282966741047 Test: 0.5914810657529391\n",
      "4.25 - Train: 0.8774217291869298 Test: 0.5894848022532566\n",
      "4.5 - Train: 0.866985347604697 Test: 0.5899506244554167\n",
      "4.75 - Train: 0.8590272052761746 Test: 0.5901828459364364\n",
      "5 - Train: 0.8501937589231083 Test: 0.5896555669985124\n",
      "5.25 - Train: 0.8409790562705022 Test: 0.5884288145207034\n",
      "5.5 - Train: 0.8335125672127047 Test: 0.5901971830985916\n",
      "5.75 - Train: 0.8271255462852602 Test: 0.5879194630872483\n",
      "6 - Train: 0.818338249754179 Test: 0.588785046728972\n"
     ]
    }
   ],
   "source": [
    "gams = [3, 3.25, 3.5, 3.75, 4, 4.25, 4.5, 4.75, 5, 5.25, 5.5, 5.75, 6]\n",
    "deep = [9, 10, 11]\n",
    "f_scores = []\n",
    "\n",
    "for el1 in deep:\n",
    "    print('***************************')\n",
    "    print('Depth: ',el1)\n",
    "    print('***************************')\n",
    "    for el2 in gams:\n",
    "\n",
    "        tune_dp_xgb = XGBClassifier(learning_rate = 0.01,  \n",
    "                              colsample_bytree = 0.6,\n",
    "                              subsample = 0.8,\n",
    "                              objective = 'binary:logistic', \n",
    "                              n_estimators = 3000,\n",
    "                              max_depth = el1, \n",
    "                              scale_pos_weight = 5,\n",
    "                              gamma = el2,\n",
    "                              verbosity = 2,\n",
    "                              tree_method = 'gpu_hist')\n",
    "\n",
    "        tune_dp_xgb.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = tune_dp_xgb.predict(X_train)\n",
    "        y_test_pred = tune_dp_xgb.predict(X_test)\n",
    "\n",
    "        train_f = f1_score(y_train, y_train_pred)\n",
    "        test_f = f1_score(y_test, y_test_pred)\n",
    "\n",
    "        f_scores.append([el, train_f, test_f])\n",
    "        print( el2,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f99a0e0",
   "metadata": {},
   "source": [
    "#### Adding L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13e636cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************\n",
      "Depth:  9\n",
      "***************************\n",
      "0 - Train: 0.8590199412583089 Test: 0.5874447188558958\n",
      "1 - Train: 0.847946669380693 Test: 0.5895815542271563\n",
      "2 - Train: 0.8397842959379095 Test: 0.5887406737508479\n",
      "3 - Train: 0.8338631755488247 Test: 0.588996399639964\n",
      "4 - Train: 0.8282843356712928 Test: 0.5885183527305282\n",
      "5 - Train: 0.8243798583948111 Test: 0.590339892665474\n",
      "***************************\n",
      "Depth:  10\n",
      "***************************\n",
      "0 - Train: 0.8840844659936942 Test: 0.5867403964939114\n",
      "1 - Train: 0.8696694818058596 Test: 0.5909222990643342\n",
      "2 - Train: 0.8618533257532689 Test: 0.5921987864778965\n",
      "3 - Train: 0.8546605499884672 Test: 0.5903159340659341\n",
      "4 - Train: 0.8492613346917982 Test: 0.5898138631951582\n",
      "5 - Train: 0.8441170514378291 Test: 0.5925841544683031\n",
      "***************************\n",
      "Depth:  11\n",
      "***************************\n",
      "0 - Train: 0.9007040543821315 Test: 0.5878333832783937\n",
      "1 - Train: 0.8867282966741047 Test: 0.5914810657529391\n",
      "2 - Train: 0.8772243395978446 Test: 0.5896849146277063\n",
      "3 - Train: 0.8700435360671551 Test: 0.5936606152588875\n",
      "4 - Train: 0.8633294528521537 Test: 0.5899263896134006\n",
      "5 - Train: 0.8584218786179217 Test: 0.5916030534351145\n",
      "***************************\n",
      "Depth:  12\n",
      "***************************\n",
      "0 - Train: 0.9122346963861345 Test: 0.5876444605796576\n",
      "1 - Train: 0.8990306946688207 Test: 0.5901168014375561\n",
      "2 - Train: 0.8882151121040452 Test: 0.5911330049261083\n",
      "3 - Train: 0.881624461989385 Test: 0.5923431407302375\n",
      "4 - Train: 0.8739856552012985 Test: 0.593171534348005\n",
      "5 - Train: 0.8675068208392881 Test: 0.5926532522227422\n"
     ]
    }
   ],
   "source": [
    "gams = [3, 3.5, 4, 4.5, 5, 5.5, 6]\n",
    "lamd = [0, 1, 2, 3, 4, 5]\n",
    "deep = [9, 10, 11, 12]\n",
    "f_scores = []\n",
    "\n",
    "for el1 in deep:\n",
    "    print('***************************')\n",
    "    print('Depth: ', el1)\n",
    "    print('***************************')\n",
    "    for el2 in lamd:\n",
    "\n",
    "        tune_dp_xgb = XGBClassifier(learning_rate = 0.01,  \n",
    "                              colsample_bytree = 0.6,\n",
    "                              subsample = 0.8,\n",
    "                              objective = 'binary:logistic', \n",
    "                              n_estimators = 3000,\n",
    "                              max_depth = el1, \n",
    "                              scale_pos_weight = 5,\n",
    "                              gamma = 4,\n",
    "                              reg_lambda = el2,\n",
    "                              verbosity = 2,\n",
    "                              tree_method = 'gpu_hist')\n",
    "\n",
    "        tune_dp_xgb.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = tune_dp_xgb.predict(X_train)\n",
    "        y_test_pred = tune_dp_xgb.predict(X_test)\n",
    "\n",
    "        train_f = f1_score(y_train, y_train_pred)\n",
    "        test_f = f1_score(y_test, y_test_pred)\n",
    "\n",
    "        f_scores.append([el, train_f, test_f])\n",
    "        print( el2,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f077a5",
   "metadata": {},
   "source": [
    "Depth 12 gives amazing results when regularized. Lets use this from now on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47952e87",
   "metadata": {},
   "source": [
    "Lets try regularizing for higher max depths too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc088a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************\n",
      "Depth:  11\n",
      "***************************\n",
      "0 - Train: 0.9007040543821315 Test: 0.5878333832783937\n",
      "1 - Train: 0.8867282966741047 Test: 0.5914810657529391\n",
      "2 - Train: 0.8772243395978446 Test: 0.5896849146277063\n",
      "3 - Train: 0.8700435360671551 Test: 0.5936606152588875\n",
      "4 - Train: 0.8633294528521537 Test: 0.5899263896134006\n",
      "5 - Train: 0.8584218786179217 Test: 0.5916030534351145\n",
      "6 - Train: 0.854552903820547 Test: 0.593325661680092\n",
      "7 - Train: 0.8484910121786886 Test: 0.592478104070067\n",
      "8 - Train: 0.8460426546293713 Test: 0.5925205855443734\n",
      "9 - Train: 0.8423550797818623 Test: 0.5923978279508432\n",
      "10 - Train: 0.8391900389888064 Test: 0.591597404076056\n",
      "***************************\n",
      "Depth:  12\n",
      "***************************\n",
      "0 - Train: 0.9122346963861345 Test: 0.5876444605796576\n",
      "1 - Train: 0.8990306946688207 Test: 0.5901168014375561\n",
      "2 - Train: 0.8882151121040452 Test: 0.5911330049261083\n",
      "3 - Train: 0.881624461989385 Test: 0.5923431407302375\n",
      "4 - Train: 0.8739856552012985 Test: 0.593171534348005\n",
      "5 - Train: 0.8675068208392881 Test: 0.5926532522227422\n",
      "6 - Train: 0.86400579800176 Test: 0.5919141240301031\n",
      "7 - Train: 0.8600654453634279 Test: 0.5925452113740769\n",
      "8 - Train: 0.8546697738738508 Test: 0.5941752069943836\n",
      "9 - Train: 0.8519652884124553 Test: 0.5935550935550935\n",
      "10 - Train: 0.8490892439198127 Test: 0.593423019431988\n",
      "***************************\n",
      "Depth:  13\n",
      "***************************\n",
      "0 - Train: 0.9216292289861472 Test: 0.5888399412628487\n",
      "1 - Train: 0.9072092138860217 Test: 0.5905177640354069\n",
      "2 - Train: 0.8979350397935039 Test: 0.5908327333813295\n",
      "3 - Train: 0.8889243791423781 Test: 0.5919875998569214\n",
      "4 - Train: 0.8818357054210346 Test: 0.5930674264007597\n",
      "5 - Train: 0.875701473750459 Test: 0.5919356745890978\n",
      "6 - Train: 0.8700456026058632 Test: 0.59261437139833\n",
      "7 - Train: 0.8662308011623079 Test: 0.5916349809885932\n",
      "8 - Train: 0.8614114307831247 Test: 0.5924024041547529\n",
      "9 - Train: 0.8573556605711938 Test: 0.5918047079337402\n",
      "10 - Train: 0.8542844715093519 Test: 0.5939021562717366\n",
      "***************************\n",
      "Depth:  14\n",
      "***************************\n",
      "0 - Train: 0.9264869063470929 Test: 0.5891272189349113\n",
      "1 - Train: 0.9115921063405847 Test: 0.5908730884055322\n",
      "2 - Train: 0.9025266855830294 Test: 0.5913432474912345\n",
      "3 - Train: 0.893855047639439 Test: 0.5915391539153915\n",
      "4 - Train: 0.8876308935310689 Test: 0.5919293218720153\n",
      "5 - Train: 0.8812074515805582 Test: 0.5899673493618284\n",
      "6 - Train: 0.8753800985634895 Test: 0.5909871498786048\n",
      "7 - Train: 0.869318477638361 Test: 0.5911794147088264\n",
      "8 - Train: 0.8660130718954249 Test: 0.5922495163276075\n",
      "9 - Train: 0.8626640487754469 Test: 0.5937371963710858\n",
      "10 - Train: 0.8584798930371286 Test: 0.5935461323392357\n"
     ]
    }
   ],
   "source": [
    "gams = [3, 3.5, 4, 4.5, 5, 5.5, 6]\n",
    "lamd = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "deep = [11, 12, 13, 14]\n",
    "f_scores = []\n",
    "\n",
    "for el1 in deep:\n",
    "    print('***************************')\n",
    "    print('Depth: ', el1)\n",
    "    print('***************************')\n",
    "    for el2 in lamd:\n",
    "\n",
    "        tune_dp_xgb = XGBClassifier(learning_rate = 0.01,  \n",
    "                              colsample_bytree = 0.6,\n",
    "                              subsample = 0.8,\n",
    "                              objective = 'binary:logistic', \n",
    "                              n_estimators = 3000,\n",
    "                              max_depth = el1, \n",
    "                              scale_pos_weight = 5,\n",
    "                              gamma = 4,\n",
    "                              reg_lambda = el2,\n",
    "                              verbosity = 2,\n",
    "                              tree_method = 'gpu_hist')\n",
    "\n",
    "        tune_dp_xgb.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = tune_dp_xgb.predict(X_train)\n",
    "        y_test_pred = tune_dp_xgb.predict(X_test)\n",
    "\n",
    "        train_f = f1_score(y_train, y_train_pred)\n",
    "        test_f = f1_score(y_test, y_test_pred)\n",
    "\n",
    "        f_scores.append([el, train_f, test_f])\n",
    "        print( el2,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a9798f",
   "metadata": {},
   "source": [
    "#### Tuning colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a3338d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 - Train: 0.8145110102045797 Test: 0.59124699569616\n",
      "0.25 - Train: 0.8293822374633467 Test: 0.5946986859990938\n",
      "0.3 - Train: 0.8370227380982226 Test: 0.5943908151025303\n",
      "0.35 - Train: 0.8457661034980622 Test: 0.5937283836753516\n",
      "0.4 - Train: 0.8506356202073727 Test: 0.5916995130999304\n",
      "0.45 - Train: 0.8549336883608992 Test: 0.5922008484918928\n",
      "0.5 - Train: 0.8587445675932831 Test: 0.5930069930069931\n",
      "0.55 - Train: 0.8622630790683262 Test: 0.5914537908458526\n",
      "0.6 - Train: 0.8660130718954249 Test: 0.5922495163276075\n"
     ]
    }
   ],
   "source": [
    "scale = [0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60]\n",
    "f_scores = []\n",
    "\n",
    "for el in scale:\n",
    "    \n",
    "    tune_wt_xgb = XGBClassifier(learning_rate = 0.01,  \n",
    "                              colsample_bytree = el,\n",
    "                              subsample = 0.8,\n",
    "                              objective = 'binary:logistic', \n",
    "                              n_estimators = 3000,\n",
    "                              max_depth = 14, \n",
    "                              scale_pos_weight = 5,\n",
    "                              gamma = 4,\n",
    "                              reg_lambda = 8,\n",
    "                              verbosity = 2,\n",
    "                              tree_method = 'gpu_hist')\n",
    "\n",
    "    \n",
    "    tune_wt_xgb.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = tune_wt_xgb.predict(X_train)\n",
    "    y_test_pred = tune_wt_xgb.predict(X_test)\n",
    "    \n",
    "    train_f = f1_score(y_train, y_train_pred)\n",
    "    test_f = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    f_scores.append([el, train_f, test_f])\n",
    "    print(el,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f5685e",
   "metadata": {},
   "source": [
    "From the above results it is obvious that colsample_bytree has a superb regularization effect on the outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5a0c9c",
   "metadata": {},
   "source": [
    "Lets try tuning subsample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "abd75bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 - Train: 0.8414658735759653 Test: 0.5914893617021277\n",
      "0.45 - Train: 0.8413862633900442 Test: 0.5914795624640184\n",
      "0.5 - Train: 0.8409279830726214 Test: 0.5959990802483329\n",
      "0.55 - Train: 0.841134680304328 Test: 0.5947438035539709\n",
      "0.6 - Train: 0.8406132776113391 Test: 0.5946596378638552\n",
      "0.65 - Train: 0.838439132181599 Test: 0.5919881305637983\n",
      "0.7 - Train: 0.8358074448644455 Test: 0.5927705330587966\n",
      "0.75 - Train: 0.8330256000798442 Test: 0.5917948717948718\n",
      "0.8 - Train: 0.8293822374633467 Test: 0.5946986859990938\n",
      "0.85 - Train: 0.8264487369985142 Test: 0.591885171790235\n",
      "0.9 - Train: 0.8237734265043581 Test: 0.5926926757867477\n",
      "0.95 - Train: 0.8197301481973015 Test: 0.5923227794900533\n",
      "1.0 - Train: 0.8146120952962737 Test: 0.5932421111421391\n"
     ]
    }
   ],
   "source": [
    "scale = [0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70]\n",
    "f_scores = []\n",
    "\n",
    "for el in scale:\n",
    "    \n",
    "    tune_wt_xgb = XGBClassifier(learning_rate = 0.01,  \n",
    "                              colsample_bytree = 0.25,\n",
    "                              subsample = el,\n",
    "                              objective = 'binary:logistic', \n",
    "                              n_estimators = 3000,\n",
    "                              max_depth = 14, \n",
    "                              scale_pos_weight = 5,\n",
    "                              gamma = 4,\n",
    "                              reg_lambda = 8,\n",
    "                              verbosity = 2,\n",
    "                              tree_method = 'gpu_hist')\n",
    "\n",
    "    \n",
    "    tune_wt_xgb.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = tune_wt_xgb.predict(X_train)\n",
    "    y_test_pred = tune_wt_xgb.predict(X_test)\n",
    "    \n",
    "    train_f = f1_score(y_train, y_train_pred)\n",
    "    test_f = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    f_scores.append([el, train_f, test_f])\n",
    "    print(el,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d50328",
   "metadata": {},
   "source": [
    "Now lets try tuning both together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "527a7b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************\n",
      "colsample_bytree:  0.2\n",
      "***************************\n",
      "0.3 - Train: 0.8119718481357914 Test: 0.5902226199798636\n",
      "0.35 - Train: 0.8173018012498467 Test: 0.5890741676492055\n",
      "0.4 - Train: 0.8208496297936192 Test: 0.5901195578614934\n",
      "0.45 - Train: 0.8206881286736677 Test: 0.5907529425015486\n",
      "0.5 - Train: 0.8222829970187499 Test: 0.5901269393511989\n",
      "0.55 - Train: 0.8225842225891514 Test: 0.5948654430807341\n",
      "0.6 - Train: 0.8229174370731949 Test: 0.5904858642288809\n",
      "0.65 - Train: 0.8217107692307691 Test: 0.5925676055546186\n",
      "0.7 - Train: 0.8194048905037808 Test: 0.592971030765776\n",
      "***************************\n",
      "colsample_bytree:  0.25\n",
      "***************************\n",
      "0.3 - Train: 0.8348095881499275 Test: 0.5884905229504452\n",
      "0.35 - Train: 0.8388799517393928 Test: 0.5904707233065443\n",
      "0.4 - Train: 0.8414658735759653 Test: 0.5914893617021277\n",
      "0.45 - Train: 0.8413862633900442 Test: 0.5914795624640184\n",
      "0.5 - Train: 0.8409279830726214 Test: 0.5959990802483329\n",
      "0.55 - Train: 0.841134680304328 Test: 0.5947438035539709\n",
      "0.6 - Train: 0.8406132776113391 Test: 0.5946596378638552\n",
      "0.65 - Train: 0.838439132181599 Test: 0.5919881305637983\n",
      "0.7 - Train: 0.8358074448644455 Test: 0.5927705330587966\n",
      "***************************\n",
      "colsample_bytree:  0.3\n",
      "***************************\n",
      "0.3 - Train: 0.8443825910931174 Test: 0.5904421101235137\n",
      "0.35 - Train: 0.8486235033935788 Test: 0.592305017962684\n",
      "0.4 - Train: 0.8511766655618164 Test: 0.5935903390617743\n",
      "0.45 - Train: 0.8517564223577132 Test: 0.5923393405574549\n",
      "0.5 - Train: 0.8513437707175276 Test: 0.5935453966046701\n",
      "0.55 - Train: 0.8487837116494242 Test: 0.5930475086906141\n",
      "0.6 - Train: 0.8489347638175625 Test: 0.592519912270576\n",
      "0.65 - Train: 0.8459024699176694 Test: 0.5929474230969007\n",
      "0.7 - Train: 0.8443837556263591 Test: 0.5949833160740997\n",
      "***************************\n",
      "colsample_bytree:  0.35\n",
      "***************************\n",
      "0.3 - Train: 0.8569741166803616 Test: 0.5908507410432956\n",
      "0.35 - Train: 0.8607673267326733 Test: 0.5912533020252421\n",
      "0.4 - Train: 0.8630664633042939 Test: 0.5912327155045601\n",
      "0.45 - Train: 0.8627613116618 Test: 0.5912288930581613\n",
      "0.5 - Train: 0.862835288645408 Test: 0.5923887587822014\n",
      "0.55 - Train: 0.8607144698180318 Test: 0.5943760984182777\n",
      "0.6 - Train: 0.8582810733011205 Test: 0.5937700145560408\n",
      "0.65 - Train: 0.8551526326572423 Test: 0.5927133046211152\n",
      "0.7 - Train: 0.8532297628781684 Test: 0.5942306576121655\n",
      "***************************\n",
      "colsample_bytree:  0.4\n",
      "***************************\n",
      "0.3 - Train: 0.862763344965749 Test: 0.5902912621359224\n",
      "0.35 - Train: 0.8672920510355223 Test: 0.5932980599647267\n",
      "0.4 - Train: 0.8692527987503255 Test: 0.5903514979948101\n",
      "0.45 - Train: 0.8694180445254523 Test: 0.5920453873884522\n",
      "0.5 - Train: 0.8692279660575771 Test: 0.5938405154578236\n",
      "0.55 - Train: 0.8678882391163094 Test: 0.5917708516757645\n",
      "0.6 - Train: 0.8651141103023081 Test: 0.5935756650419871\n",
      "0.65 - Train: 0.8603374983897978 Test: 0.5936441173034234\n",
      "0.7 - Train: 0.8581707912522807 Test: 0.5933103730079972\n",
      "***************************\n",
      "colsample_bytree:  0.45\n",
      "***************************\n",
      "0.3 - Train: 0.8717453187433079 Test: 0.5893428063943161\n",
      "0.35 - Train: 0.8745121663741848 Test: 0.5923593369377934\n",
      "0.4 - Train: 0.8770685579196218 Test: 0.5905896366885051\n",
      "0.45 - Train: 0.8779974758098443 Test: 0.5914974468590428\n",
      "0.5 - Train: 0.8759311719651662 Test: 0.5921536091027617\n",
      "0.55 - Train: 0.8743258103367022 Test: 0.5931770987837437\n",
      "0.6 - Train: 0.870980361474063 Test: 0.5942345104049992\n",
      "0.65 - Train: 0.8686311737626466 Test: 0.5928634621055736\n",
      "0.7 - Train: 0.8634518422753716 Test: 0.5918893577121427\n",
      "***************************\n",
      "colsample_bytree:  0.5\n",
      "***************************\n",
      "0.3 - Train: 0.8786315789473683 Test: 0.5881792183031458\n",
      "0.35 - Train: 0.8823234058296557 Test: 0.5885379277339077\n",
      "0.4 - Train: 0.8835732430143945 Test: 0.5914987744365396\n",
      "0.45 - Train: 0.8836840015879316 Test: 0.5923532579429187\n",
      "0.5 - Train: 0.8824586438348925 Test: 0.5927566596827297\n",
      "0.55 - Train: 0.8807595938283002 Test: 0.5935784196705659\n",
      "0.6 - Train: 0.877479702567067 Test: 0.5918585331117968\n",
      "0.65 - Train: 0.8724916387959866 Test: 0.5925005914360066\n",
      "0.7 - Train: 0.8693252811328613 Test: 0.592256467676351\n",
      "***************************\n",
      "colsample_bytree:  0.55\n",
      "***************************\n",
      "0.3 - Train: 0.8819209636517329 Test: 0.5889812765448347\n",
      "0.35 - Train: 0.8869408139411328 Test: 0.590576669464093\n",
      "0.4 - Train: 0.8881795935737845 Test: 0.5893725607925547\n",
      "0.45 - Train: 0.8886346097554485 Test: 0.5916356207186637\n",
      "0.5 - Train: 0.8849201091708842 Test: 0.5942870830588658\n",
      "0.55 - Train: 0.8845512090473289 Test: 0.5905807915000297\n",
      "0.6 - Train: 0.8807891127756092 Test: 0.5923589621518686\n",
      "0.65 - Train: 0.8768115942028986 Test: 0.590255496137849\n",
      "0.7 - Train: 0.8715553235908142 Test: 0.5928469919469446\n",
      "***************************\n",
      "colsample_bytree:  0.6\n",
      "***************************\n",
      "0.3 - Train: 0.8885517314807421 Test: 0.5888915547024952\n",
      "0.35 - Train: 0.8909702209414023 Test: 0.5893964012758018\n",
      "0.4 - Train: 0.8931628504172908 Test: 0.5921497584541062\n",
      "0.45 - Train: 0.892720613788863 Test: 0.5890799396681751\n",
      "0.5 - Train: 0.8903225806451613 Test: 0.5912949250496659\n",
      "0.55 - Train: 0.8885577434805747 Test: 0.5909637106464792\n",
      "0.6 - Train: 0.8847733354529317 Test: 0.5929293533528743\n",
      "0.65 - Train: 0.8816960160519577 Test: 0.5912129894937919\n",
      "0.7 - Train: 0.8754325259515571 Test: 0.5915024922857822\n"
     ]
    }
   ],
   "source": [
    "sub = [0.30, 0.35,0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70]\n",
    "scale = [0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60]\n",
    "f_scores = []\n",
    "\n",
    "for el1 in scale:\n",
    "    print('***************************')\n",
    "    print('colsample_bytree: ', el1)\n",
    "    print('***************************')\n",
    "    for el2 in sub:\n",
    "\n",
    "        tune_dp_xgb = XGBClassifier(learning_rate = 0.01,  \n",
    "                              colsample_bytree = el1,\n",
    "                              subsample = el2,\n",
    "                              objective = 'binary:logistic', \n",
    "                              n_estimators = 3000,\n",
    "                              max_depth = 14, \n",
    "                              scale_pos_weight = 5,\n",
    "                              gamma = 4,\n",
    "                              reg_lambda = 8,\n",
    "                              verbosity = 2,\n",
    "                              tree_method = 'gpu_hist')\n",
    "\n",
    "        tune_dp_xgb.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = tune_dp_xgb.predict(X_train)\n",
    "        y_test_pred = tune_dp_xgb.predict(X_test)\n",
    "\n",
    "        train_f = f1_score(y_train, y_train_pred)\n",
    "        test_f = f1_score(y_test, y_test_pred)\n",
    "\n",
    "        f_scores.append([el, train_f, test_f])\n",
    "        print( el2,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d2b625",
   "metadata": {},
   "source": [
    "We fix **colsample_bytree = 0.25** and **subsample = 0.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0ac3bf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 - Train: 0.8169880650582505 Test: 0.5845963075227336\n",
      "2.2 - Train: 0.8328329997776296 Test: 0.5887655566767575\n",
      "2.4 - Train: 0.8426905047421781 Test: 0.5874264560058174\n",
      "2.6 - Train: 0.8518080704959434 Test: 0.5894709543568465\n",
      "2.8 - Train: 0.8538420773714892 Test: 0.5916767573768402\n",
      "3.0 - Train: 0.8563334470004984 Test: 0.5922208281053951\n",
      "3.2 - Train: 0.8552022068391194 Test: 0.5929828911480288\n",
      "3.4000000000000004 - Train: 0.8554500530387312 Test: 0.5896081562461614\n",
      "3.6 - Train: 0.854670478250792 Test: 0.5939886074415222\n",
      "3.8 - Train: 0.8522648619549335 Test: 0.5942595824056802\n",
      "4.0 - Train: 0.8498583569405099 Test: 0.5935560859188543\n",
      "4.2 - Train: 0.8489619156795313 Test: 0.5928165007112376\n",
      "4.4 - Train: 0.8466419615208893 Test: 0.5935885392202913\n",
      "4.6 - Train: 0.8449170781111534 Test: 0.5945914442242686\n",
      "4.800000000000001 - Train: 0.8424533064109035 Test: 0.5933849890135307\n",
      "5.0 - Train: 0.8409279830726214 Test: 0.5959990802483329\n",
      "5.2 - Train: 0.8402879146323048 Test: 0.5947212065813527\n",
      "5.4 - Train: 0.8380976283097001 Test: 0.59336146914566\n",
      "5.6 - Train: 0.8363681903569192 Test: 0.5934600588368408\n",
      "5.800000000000001 - Train: 0.8350796469028984 Test: 0.5903851560303627\n",
      "6.0 - Train: 0.8331088160455021 Test: 0.5937115363097235\n",
      "6.2 - Train: 0.8322575821765893 Test: 0.591159913048325\n",
      "6.4 - Train: 0.8305480950959913 Test: 0.5914992786594162\n",
      "6.6000000000000005 - Train: 0.8296318378297809 Test: 0.5891001547645368\n",
      "6.800000000000001 - Train: 0.8292283245605324 Test: 0.5901820187534473\n",
      "7.0 - Train: 0.827358981346149 Test: 0.5900972687805682\n",
      "7.2 - Train: 0.8254894206051018 Test: 0.5895530543110044\n",
      "7.4 - Train: 0.8267240952522402 Test: 0.5891143106457243\n",
      "7.6000000000000005 - Train: 0.8237673581136078 Test: 0.5883120413155749\n",
      "7.800000000000001 - Train: 0.8222665386414555 Test: 0.5882925247283931\n",
      "8.0 - Train: 0.8220034457297564 Test: 0.5882543452445212\n"
     ]
    }
   ],
   "source": [
    "scale = list(np.linspace(2,8,31))\n",
    "f_scores = []\n",
    "\n",
    "for el in scale:\n",
    "    \n",
    "    tune_wt_xgb = XGBClassifier(learning_rate = 0.01,  \n",
    "                              colsample_bytree = 0.25,\n",
    "                              subsample = 0.50,\n",
    "                              objective = 'binary:logistic', \n",
    "                              n_estimators = 3000,\n",
    "                              max_depth = 14, \n",
    "                              scale_pos_weight = el,\n",
    "                              gamma = 4,\n",
    "                              reg_lambda = 8,\n",
    "                              verbosity = 2,\n",
    "                              tree_method = 'gpu_hist')\n",
    "\n",
    "    \n",
    "    tune_wt_xgb.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = tune_wt_xgb.predict(X_train)\n",
    "    y_test_pred = tune_wt_xgb.predict(X_test)\n",
    "    \n",
    "    train_f = f1_score(y_train, y_train_pred)\n",
    "    test_f = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    f_scores.append([el, train_f, test_f])\n",
    "    print(el,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d989251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573a375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44c741f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8223e5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e5002f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18817153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acfeda88",
   "metadata": {},
   "source": [
    "### The Ultra Mega Super Max Pro Search \n",
    "\n",
    "Running cos Gautham inte laptop verm pazham aan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b00bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'gamma': [3, 3.5, 4, 4.5, 5, 5.5, 6],\n",
    "        'subsample': [0.2, 0.3, 0.4, 0.5, 0.6, 0.8],\n",
    "        'colsample_bytree': list(np.linspace(0.2, 0.9, 10)),\n",
    "        'max_depth': [12, 13, 14, 15],\n",
    "        'reg_lambda' : [5, 6, 7, 8, 9]\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(learning_rate = 0.01, n_estimators = 3000, objective='binary:logistic', scale_pos_weight = 5)\n",
    "skf = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 42)\n",
    "grid = GridSearchCV(estimator = xgb, param_grid = params, scoring = 'f1', cv = skf.split(X, y), verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e3483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 22500 candidates, totalling 67500 fits\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=1, subsample=0.6;, score=0.578 total time=  32.4s\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=1, subsample=0.6;, score=0.574 total time=  33.3s\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=1, subsample=0.6;, score=0.580 total time=  34.2s\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=1, subsample=0.8;, score=0.579 total time=  38.1s\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=1, subsample=0.8;, score=0.575 total time=  37.1s\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=1, subsample=0.8;, score=0.581 total time=  36.5s\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=1, subsample=1.0;, score=0.576 total time=  37.7s\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=1, subsample=1.0;, score=0.574 total time=  37.7s\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=1, subsample=1.0;, score=0.578 total time=  37.5s\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=5, subsample=0.6;, score=0.577 total time=  34.4s\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=5, subsample=0.6;, score=0.575 total time=  32.3s\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=5, subsample=0.6;, score=0.580 total time=  33.3s\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=5, subsample=0.8;, score=0.579 total time=  37.1s\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=5, subsample=0.8;, score=0.575 total time=  38.6s\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=5, subsample=0.8;, score=0.580 total time=  38.2s\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=5, subsample=1.0;, score=0.577 total time=  39.0s\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=5, subsample=1.0;, score=0.574 total time=  39.1s\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=5, subsample=1.0;, score=0.577 total time=  39.2s\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=6, subsample=0.6;, score=0.578 total time=  35.1s\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=6, subsample=0.6;, score=0.574 total time=  35.2s\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=6, subsample=0.6;, score=0.578 total time=  35.6s\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=6, subsample=0.8;, score=0.579 total time=  38.9s\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=6, subsample=0.8;, score=0.575 total time=  38.7s\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=6, subsample=0.8;, score=0.580 total time=  38.3s\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=6, subsample=1.0;, score=0.577 total time=  39.1s\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=6, subsample=1.0;, score=0.574 total time=  39.2s\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=6, subsample=1.0;, score=0.578 total time=  39.2s\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=7, subsample=0.6;, score=0.577 total time=  35.4s\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=7, subsample=0.6;, score=0.574 total time=  35.5s\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=7, subsample=0.6;, score=0.579 total time=  35.3s\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=7, subsample=0.8;, score=0.579 total time=  38.7s\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=7, subsample=0.8;, score=0.575 total time=  38.7s\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=7, subsample=0.8;, score=0.579 total time=  38.4s\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=7, subsample=1.0;, score=0.577 total time=  39.4s\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=7, subsample=1.0;, score=0.572 total time=  39.2s\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=7, subsample=1.0;, score=0.578 total time=  39.4s\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=8, subsample=0.6;, score=0.577 total time=  35.5s\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=8, subsample=0.6;, score=0.575 total time=  35.3s\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=8, subsample=0.6;, score=0.579 total time=  35.4s\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=8, subsample=0.8;, score=0.577 total time=  38.7s\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=8, subsample=0.8;, score=0.575 total time=  38.6s\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=8, subsample=0.8;, score=0.580 total time=  38.6s\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=8, subsample=1.0;, score=0.578 total time=  39.5s\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=8, subsample=1.0;, score=0.573 total time=  39.3s\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=1000, reg_lambda=8, subsample=1.0;, score=0.577 total time=  39.6s\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=1, subsample=0.6;, score=0.583 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=1, subsample=0.6;, score=0.584 total time= 1.1min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=1, subsample=0.6;, score=0.586 total time= 1.1min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=1, subsample=0.8;, score=0.582 total time= 1.3min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=1, subsample=0.8;, score=0.581 total time= 1.3min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=1, subsample=0.8;, score=0.587 total time= 1.2min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=1, subsample=1.0;, score=0.579 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=1, subsample=1.0;, score=0.581 total time= 1.3min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=1, subsample=1.0;, score=0.584 total time= 1.2min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=5, subsample=0.6;, score=0.585 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=5, subsample=0.6;, score=0.584 total time= 1.2min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=5, subsample=0.6;, score=0.586 total time= 1.2min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=5, subsample=0.8;, score=0.586 total time= 1.3min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=5, subsample=0.8;, score=0.584 total time= 1.3min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=5, subsample=0.8;, score=0.587 total time= 1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=5, subsample=1.0;, score=0.582 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=5, subsample=1.0;, score=0.580 total time= 1.3min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=5, subsample=1.0;, score=0.583 total time= 1.3min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=6, subsample=0.6;, score=0.584 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=6, subsample=0.6;, score=0.582 total time= 1.2min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=6, subsample=0.6;, score=0.587 total time= 1.2min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=6, subsample=0.8;, score=0.585 total time= 1.3min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=6, subsample=0.8;, score=0.583 total time= 1.3min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=6, subsample=0.8;, score=0.587 total time= 1.3min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=6, subsample=1.0;, score=0.582 total time= 1.3min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=6, subsample=1.0;, score=0.579 total time= 1.3min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=6, subsample=1.0;, score=0.584 total time= 1.3min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=7, subsample=0.6;, score=0.585 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=7, subsample=0.6;, score=0.583 total time= 1.2min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=7, subsample=0.6;, score=0.587 total time= 1.1min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=7, subsample=0.8;, score=0.585 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=7, subsample=0.8;, score=0.583 total time= 1.3min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=7, subsample=0.8;, score=0.587 total time= 1.2min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=7, subsample=1.0;, score=0.582 total time= 1.3min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=7, subsample=1.0;, score=0.580 total time= 1.2min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=7, subsample=1.0;, score=0.583 total time= 1.3min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=8, subsample=0.6;, score=0.584 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=8, subsample=0.6;, score=0.584 total time= 1.2min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=8, subsample=0.6;, score=0.587 total time= 1.2min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=8, subsample=0.8;, score=0.584 total time= 1.3min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=8, subsample=0.8;, score=0.583 total time= 1.3min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=8, subsample=0.8;, score=0.587 total time= 1.3min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=8, subsample=1.0;, score=0.582 total time= 1.3min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=8, subsample=1.0;, score=0.580 total time= 1.2min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=2000, reg_lambda=8, subsample=1.0;, score=0.584 total time= 1.3min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=1, subsample=0.6;, score=0.586 total time= 1.7min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=1, subsample=0.6;, score=0.586 total time= 1.7min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=1, subsample=0.6;, score=0.588 total time= 1.7min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=1, subsample=0.8;, score=0.585 total time= 1.9min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=1, subsample=0.8;, score=0.585 total time= 1.9min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=1, subsample=0.8;, score=0.588 total time= 1.9min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=1, subsample=1.0;, score=0.582 total time= 1.8min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=1, subsample=1.0;, score=0.585 total time= 1.8min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=1, subsample=1.0;, score=0.586 total time= 1.8min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=5, subsample=0.6;, score=0.586 total time= 1.7min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=5, subsample=0.6;, score=0.589 total time= 1.7min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=5, subsample=0.6;, score=0.589 total time= 1.8min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=5, subsample=0.8;, score=0.587 total time= 1.9min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=5, subsample=0.8;, score=0.587 total time= 1.9min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=5, subsample=0.8;, score=0.591 total time= 1.9min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=5, subsample=1.0;, score=0.584 total time= 1.8min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=5, subsample=1.0;, score=0.585 total time= 1.9min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=5, subsample=1.0;, score=0.586 total time= 1.9min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=6, subsample=0.6;, score=0.587 total time= 1.8min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=6, subsample=0.6;, score=0.587 total time= 1.8min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=6, subsample=0.6;, score=0.590 total time= 1.8min\n",
      "[CV 1/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=6, subsample=0.8;, score=0.586 total time= 1.9min\n",
      "[CV 2/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=6, subsample=0.8;, score=0.587 total time= 1.9min\n",
      "[CV 3/3] END colsample_bytree=0.4, gamma=1, max_depth=8, n_estimators=3000, reg_lambda=6, subsample=0.8;, score=0.589 total time= 1.9min\n"
     ]
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3c63d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6a707a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5cf357e",
   "metadata": {},
   "source": [
    "## Using LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09ad1521",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = LGBMClassifier(boosting_type = 'goss',\n",
    "                            learning_rate = 0.003,\n",
    "                            n_estimators = 3000,\n",
    "                            objective = 'binary',\n",
    "                            num_leaves = 50,\n",
    "                            max_depth = -1,\n",
    "                            is_unbalance = True,\n",
    "                            reg_lambda = 4\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e5df7652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vishnu\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='goss', class_weight='balanced',\n",
       "               learning_rate=0.003, n_estimators=3000, num_leaves=50,\n",
       "               objective='binary', reg_lambda=4)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_model.fit(X_train, y_train, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fafc232e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82     35899\n",
      "           1       0.75      0.56      0.64     22201\n",
      "\n",
      "    accuracy                           0.76     58100\n",
      "   macro avg       0.76      0.72      0.73     58100\n",
      "weighted avg       0.76      0.76      0.75     58100\n",
      "\n",
      "0.644318766066838\n"
     ]
    }
   ],
   "source": [
    "y_pred20 = lgbm_model.predict(X_train)\n",
    "print(classification_report(y_pred20, y_train))\n",
    "print(f1_score(y_pred20, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "83ea19c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.79     15265\n",
      "           1       0.69      0.51      0.58      9635\n",
      "\n",
      "    accuracy                           0.72     24900\n",
      "   macro avg       0.71      0.68      0.69     24900\n",
      "weighted avg       0.72      0.72      0.71     24900\n",
      "\n",
      "0.584837115121196\n"
     ]
    }
   ],
   "source": [
    "y_pred21 = lgbm_model.predict(X_test)\n",
    "print(classification_report(y_pred21, y_test))\n",
    "print(f1_score(y_pred21, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ce06f6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lightgbm.plot_importance(lgbm_model, max_num_features = 20, importance_type = 'gain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb012ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ff400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c12d34d",
   "metadata": {},
   "source": [
    "## Tuning LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed2834e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goss - Train: 0.6611660593440916 Test: 0.5980633908702714\n",
      "gbdt - Train: 0.6652598671355998 Test: 0.5951054034407561\n"
     ]
    }
   ],
   "source": [
    "boosts = ['goss', 'gbdt']\n",
    "f_scores = []\n",
    "\n",
    "for el in boosts:\n",
    "    \n",
    "    tune_boost_lgbm = LGBMClassifier(boosting_type = el,\n",
    "                            learning_rate = 0.003,\n",
    "                            n_estimators = 3000,\n",
    "                            num_leaves = 50,\n",
    "                            max_depth = -1,\n",
    "                            objective = 'binary',\n",
    "                            class_weight = 'balanced'\n",
    "                            )\n",
    "    \n",
    "    tune_boost_lgbm.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = tune_boost_lgbm.predict(X_train)\n",
    "    y_test_pred = tune_boost_lgbm.predict(X_test)\n",
    "    \n",
    "    train_f = f1_score(y_train, y_train_pred)\n",
    "    test_f = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    f_scores.append([el, train_f, test_f])\n",
    "    print(el,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6a7ec6",
   "metadata": {},
   "source": [
    "Best boosting method seems to be **GOSS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c68fc57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 - Train: 0.6063800416635293 Test: 0.5933232169954477\n",
      "0.003 - Train: 0.6349116535068542 Test: 0.5983801810385897\n",
      "0.01 - Train: 0.720207112685652 Test: 0.5934244182419366\n",
      "0.03 - Train: 0.8893802734943265 Test: 0.5722334004024145\n",
      "0.1 - Train: 0.992414552161109 Test: 0.5310119695321002\n",
      "0.3 - Train: 1.0 Test: 0.5056694450702109\n"
     ]
    }
   ],
   "source": [
    "lrs = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3]\n",
    "f_scores = []\n",
    "\n",
    "for el in lrs:\n",
    "    \n",
    "    tune_lr_lgbm = LGBMClassifier(boosting_type = 'goss',\n",
    "                            learning_rate = el,\n",
    "                            n_estimators = 3000,\n",
    "                            objective = 'binary',\n",
    "                            class_weight = 'balanced'\n",
    "                            )\n",
    "    \n",
    "    tune_lr_lgbm.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = tune_lr_lgbm.predict(X_train)\n",
    "    y_test_pred = tune_lr_lgbm.predict(X_test)\n",
    "    \n",
    "    train_f = f1_score(y_train, y_train_pred)\n",
    "    test_f = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    f_scores.append([el, train_f, test_f])\n",
    "    print(el,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcf31cb",
   "metadata": {},
   "source": [
    "Best LR seems to be between **0.001 - 0.01**. We can also attempt LR decay (later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7aeeecab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 - Train: 0.6063325728897692 Test: 0.591982234689107\n",
      "2000 - Train: 0.6210266459674751 Test: 0.5965989607935758\n",
      "3000 - Train: 0.6349116535068542 Test: 0.5983801810385897\n",
      "4000 - Train: 0.6482737121034995 Test: 0.5980309761075759\n",
      "5000 - Train: 0.6605889133396207 Test: 0.5987430505197003\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-2a4e3dcf8864>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtune_est_lgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtune_est_lgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtune_est_lgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    982\u001b[0m                 pred_leaf=False, pred_contrib=False, **kwargs):\n\u001b[0;32m    983\u001b[0m         \u001b[1;34m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 984\u001b[1;33m         result = self.predict_proba(X, raw_score, start_iteration, num_iteration,\n\u001b[0m\u001b[0;32m    985\u001b[0m                                     pred_leaf, pred_contrib, **kwargs)\n\u001b[0;32m    986\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_objective\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mraw_score\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    995\u001b[0m                       pred_leaf=False, pred_contrib=False, **kwargs):\n\u001b[0;32m    996\u001b[0m         \u001b[1;34m\"\"\"Docstring is set after definition, using a template.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 997\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    998\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_objective\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mraw_score\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m             _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    801\u001b[0m                              \u001b[1;34mf\"match the input. Model n_features_ is {self._n_features} and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m                              f\"input n_features is {n_features}\")\n\u001b[1;32m--> 803\u001b[1;33m         return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n\u001b[0m\u001b[0;32m    804\u001b[0m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[0;32m   3536\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3537\u001b[0m                 \u001b[0mnum_iteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3538\u001b[1;33m         return predictor.predict(data, start_iteration, num_iteration,\n\u001b[0m\u001b[0;32m   3539\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3540\u001b[0m                                  data_has_header, is_reshape)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m             \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[1;34m(self, mat, start_iteration, num_iteration, predict_type)\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 938\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m     def __create_sparse_native(self, cs, out_shape, out_ptr_indptr, out_ptr_indices, out_ptr_data,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[1;34m(mat, start_iteration, num_iteration, predict_type, preds)\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Wrong length of pre-allocated predict array\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[0mout_num_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m             _safe_call(_LIB.LGBM_BoosterPredictForMat(\n\u001b[0m\u001b[0;32m    909\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m                 \u001b[0mptr_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# lrs = [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009]\n",
    "ests = [1000, 2000, 3000, 4000, 5000, 6000]\n",
    "f_scores = []\n",
    "\n",
    "for el in ests:\n",
    "    \n",
    "    tune_est_lgbm = LGBMClassifier(boosting_type = 'goss',\n",
    "                            learning_rate = 0.003,\n",
    "                            n_estimators = el,\n",
    "                            objective = 'binary',\n",
    "                            class_weight = 'balanced'\n",
    "                            )\n",
    "    \n",
    "    tune_est_lgbm.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = tune_est_lgbm.predict(X_train)\n",
    "    y_test_pred = tune_est_lgbm.predict(X_test)\n",
    "    \n",
    "    train_f = f1_score(y_train, y_train_pred)\n",
    "    test_f = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    f_scores.append([el, train_f, test_f])\n",
    "    print(el,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [0.001, 0.002, 0.003, 0.004, 0.005]\n",
    "ests = [2000, 2500, 3000, 3500, 4000, 4500, 5000]\n",
    "f_scores = []\n",
    "\n",
    "for el1 in ests:\n",
    "    for el2 in lrs:\n",
    "    \n",
    "        tune_est_lgbm = LGBMClassifier(boosting_type = 'goss',\n",
    "                                learning_rate = el2,\n",
    "                                n_estimators = el1,\n",
    "                                objective = 'binary',\n",
    "                                class_weight = 'balanced'\n",
    "                                )\n",
    "\n",
    "        tune_est_lgbm.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = tune_est_lgbm.predict(X_train)\n",
    "        y_test_pred = tune_est_lgbm.predict(X_test)\n",
    "\n",
    "        train_f = f1_score(y_train, y_train_pred)\n",
    "        test_f = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#         f_scores.append([el, train_f, test_f])\n",
    "        print(el1, el2,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756c84c5",
   "metadata": {},
   "source": [
    "Overall best performance seems to be given by learning rate of **0.003**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0fd73ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 - Train: 0.6282484141600164 Test: 0.5980642479662727\n",
      "2625 - Train: 0.6300660962238049 Test: 0.5983606557377049\n",
      "2750 - Train: 0.6316707717569786 Test: 0.5977640342530922\n",
      "2875 - Train: 0.6332288401253918 Test: 0.5976546222989464\n",
      "3000 - Train: 0.6349116535068542 Test: 0.5983801810385897\n",
      "3125 - Train: 0.6370126021183928 Test: 0.5985923893594177\n",
      "3250 - Train: 0.6382901835264966 Test: 0.5984364743092438\n",
      "3375 - Train: 0.6394438270488202 Test: 0.5979911515006576\n",
      "3500 - Train: 0.6411463452485645 Test: 0.5975704625695648\n"
     ]
    }
   ],
   "source": [
    "ests = [2500, 2625, 2750, 2875, 3000, 3125, 3250, 3375, 3500]\n",
    "f_scores = []\n",
    "\n",
    "for el in ests:\n",
    "    \n",
    "    tune_est_lgbm = LGBMClassifier(boosting_type = 'goss',\n",
    "                            learning_rate = 0.003,\n",
    "                            n_estimators = el,\n",
    "                            objective = 'binary',\n",
    "                            class_weight = 'balanced'\n",
    "                            )\n",
    "\n",
    "    tune_est_lgbm.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = tune_est_lgbm.predict(X_train)\n",
    "    y_test_pred = tune_est_lgbm.predict(X_test)\n",
    "\n",
    "    train_f = f1_score(y_train, y_train_pred)\n",
    "    test_f = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    f_scores.append([el, train_f, test_f])\n",
    "    print(el,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a67bd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "939507f7",
   "metadata": {},
   "source": [
    "Let us fix **n_est = 3000** and **lr = 0.003** for all future experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50777e0f",
   "metadata": {},
   "source": [
    "#### L2 Regularization across various num_leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0b32c433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************\n",
      "L2 lambda:  1.0\n",
      "***************************\n",
      "30 - Train: 0.6399422546466964 Test: 0.6002625925041776 0.06610383961623043\n",
      "35 - Train: 0.6476190476190475 Test: 0.5981341944743452 0.08273202502356647\n",
      "40 - Train: 0.6557947492793893 Test: 0.5998204130499851 0.09331849168784398\n",
      "45 - Train: 0.6623556100232068 Test: 0.6000360382004924 0.10385971484247954\n",
      "50 - Train: 0.6701685613484908 Test: 0.5975932611311673 0.12144598163631862\n",
      "55 - Train: 0.6778790736665619 Test: 0.5994431666868417 0.13084794579149195\n",
      "60 - Train: 0.6859712797853874 Test: 0.5994800798017049 0.14427702086830294\n",
      "***************************\n",
      "L2 lambda:  2.0\n",
      "***************************\n",
      "30 - Train: 0.6389662643144538 Test: 0.5981386469395059 0.06825778201065995\n",
      "35 - Train: 0.6465974684854916 Test: 0.5985645933014354 0.08024676989182848\n",
      "40 - Train: 0.6548144303140411 Test: 0.5984431137724552 0.09419661659440506\n",
      "45 - Train: 0.6625862742544602 Test: 0.5993391408831481 0.10552812098691751\n",
      "50 - Train: 0.669539104321713 Test: 0.5994354015256171 0.11694955389300608\n",
      "55 - Train: 0.6772874960695944 Test: 0.5982854382999276 0.13204743540835112\n",
      "60 - Train: 0.6851238365672818 Test: 0.5973113721690687 0.14701287885970105\n",
      "***************************\n",
      "L2 lambda:  3.0\n",
      "***************************\n",
      "30 - Train: 0.6397958920702007 Test: 0.5995594975891421 0.06710992760993888\n",
      "35 - Train: 0.6470588235294117 Test: 0.5988396435193493 0.08052102183262422\n",
      "40 - Train: 0.6541643970637825 Test: 0.6002517532817839 0.08981672021320969\n",
      "45 - Train: 0.6620040559513286 Test: 0.599783731827466 0.10373793222814669\n",
      "50 - Train: 0.6695227397403412 Test: 0.5997230750707363 0.11638649165095424\n",
      "55 - Train: 0.6764598062319979 Test: 0.5990338164251209 0.12925145072599623\n",
      "60 - Train: 0.683604104879137 Test: 0.5984995159728945 0.1421965876913037\n",
      "***************************\n",
      "L2 lambda:  4.0\n",
      "***************************\n",
      "30 - Train: 0.6385952245887268 Test: 0.5999880575625485 0.06434655913489329\n",
      "35 - Train: 0.6462730913318693 Test: 0.6003467447838823 0.07649970112608828\n",
      "40 - Train: 0.6546010838281432 Test: 0.5985016481869944 0.0937331347559151\n",
      "45 - Train: 0.6616197091495617 Test: 0.5995799579957996 0.10347202291607749\n",
      "50 - Train: 0.6696265343431707 Test: 0.5996150144369586 0.11676078520474202\n",
      "55 - Train: 0.6763811720306112 Test: 0.5984784446322907 0.1301679752997361\n",
      "60 - Train: 0.6830229320444455 Test: 0.5984251968503937 0.14136726802163915\n",
      "***************************\n",
      "L2 lambda:  5.0\n",
      "***************************\n",
      "30 - Train: 0.6394178665428085 Test: 0.6007391511683358 0.06438520828757244\n",
      "35 - Train: 0.6457380564814097 Test: 0.5987565758010521 0.07846507675928728\n",
      "40 - Train: 0.6534792077154412 Test: 0.5987780040733198 0.0913547312526585\n",
      "45 - Train: 0.661793777962751 Test: 0.6004327443202309 0.10219468245688182\n",
      "50 - Train: 0.6684216013344453 Test: 0.5983409473431114 0.11712495075344892\n",
      "55 - Train: 0.6769343601026769 Test: 0.5984565296032799 0.1311337191882933\n",
      "60 - Train: 0.6830215412064125 Test: 0.5986098519190087 0.14101286341479147\n"
     ]
    }
   ],
   "source": [
    "leaves = [30, 35, 40, 45, 50, 55, 60]\n",
    "regs = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "f_scores = []\n",
    "\n",
    "for el1 in regs:\n",
    "    print('***************************')\n",
    "    print('L2 lambda: ',el1)\n",
    "    print('***************************')\n",
    "    for el2 in leaves:\n",
    "\n",
    "        tune_reg_lgbm = LGBMClassifier(boosting_type = 'goss',\n",
    "                                learning_rate = 0.003,\n",
    "                                n_estimators = 3500,\n",
    "                                objective = 'binary',\n",
    "                                num_leaves = el2,\n",
    "                                max_depth = -1,\n",
    "                                is_unbalance = True,\n",
    "                                reg_lambda = el1,\n",
    "                                colsample_bytree = 0.90\n",
    "                                )\n",
    "\n",
    "        tune_reg_lgbm.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = tune_reg_lgbm.predict(X_train)\n",
    "        y_test_pred = tune_reg_lgbm.predict(X_test)\n",
    "\n",
    "        train_f = f1_score(y_train, y_train_pred)\n",
    "        test_f = f1_score(y_test, y_test_pred)\n",
    "\n",
    "        f_scores.append([el, train_f, test_f])\n",
    "        print(el2,\"- Train:\", train_f, \"Test:\", test_f, (train_f-test_f)/(test_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d692a1ca",
   "metadata": {},
   "source": [
    "We use 40 leaves from now on due to better overall performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c608e7",
   "metadata": {},
   "source": [
    "#### L2 Regularization across various num_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea6466eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************\n",
      "Depth:  2000\n",
      "***************************\n",
      "0.0 - Train: 0.6302563841174372 Test: 0.5971754417065532\n",
      "2.0 - Train: 0.6293702732296097 Test: 0.599020706742965\n",
      "4.0 - Train: 0.6295165394402036 Test: 0.5966694224636825\n",
      "6.0 - Train: 0.629272389484132 Test: 0.5981584228544445\n",
      "8.0 - Train: 0.630227532731664 Test: 0.5964353163361662\n",
      "10.0 - Train: 0.6291345198991675 Test: 0.5971910775404226\n",
      "12.0 - Train: 0.6299725302675755 Test: 0.5977215040434449\n",
      "14.0 - Train: 0.629264324571661 Test: 0.5984066096193568\n",
      "16.0 - Train: 0.6292785810484588 Test: 0.5971575160700595\n",
      "***************************\n",
      "Depth:  3000\n",
      "***************************\n",
      "0.0 - Train: 0.6481940144478844 Test: 0.5996420047732697\n",
      "2.0 - Train: 0.6468056593562354 Test: 0.6005966587112171\n",
      "4.0 - Train: 0.6463512016691997 Test: 0.6001906123421491\n",
      "6.0 - Train: 0.6470300219043937 Test: 0.5993434795583408\n",
      "8.0 - Train: 0.646592546839613 Test: 0.599058009896858\n",
      "10.0 - Train: 0.6459218078398065 Test: 0.5975326300733059\n",
      "12.0 - Train: 0.6462211922235096 Test: 0.5980561683859043\n",
      "14.0 - Train: 0.6458809921603907 Test: 0.598713979518933\n",
      "16.0 - Train: 0.6454468260298999 Test: 0.5982834664441531\n",
      "***************************\n",
      "Depth:  4000\n",
      "***************************\n",
      "0.0 - Train: 0.6648203788373612 Test: 0.5999637921670389\n",
      "2.0 - Train: 0.6639669766955795 Test: 0.6008914588603783\n",
      "4.0 - Train: 0.6628213493409891 Test: 0.5992419228686602\n",
      "6.0 - Train: 0.6633448986512926 Test: 0.5989150090415913\n",
      "8.0 - Train: 0.6623961669661226 Test: 0.5989762119843421\n",
      "10.0 - Train: 0.6607561929595829 Test: 0.5987743330930065\n",
      "12.0 - Train: 0.6616353510643835 Test: 0.5984375\n",
      "14.0 - Train: 0.6610848198034219 Test: 0.5990639625585022\n",
      "16.0 - Train: 0.6612597156151706 Test: 0.5976459284170069\n",
      "***************************\n",
      "Depth:  5000\n",
      "***************************\n",
      "0.0 - Train: 0.6812658495350803 Test: 0.5981513013865241\n",
      "2.0 - Train: 0.6787779567479074 Test: 0.5998299732815157\n",
      "4.0 - Train: 0.677968782957182 Test: 0.599102377486657\n",
      "6.0 - Train: 0.6778374960480557 Test: 0.5992345544013121\n",
      "8.0 - Train: 0.6767886745783227 Test: 0.5986882060002429\n",
      "10.0 - Train: 0.6755005268703899 Test: 0.5988857938718662\n",
      "12.0 - Train: 0.6764032525459857 Test: 0.5987160852713178\n",
      "14.0 - Train: 0.6750288653301144 Test: 0.5985242530543123\n",
      "16.0 - Train: 0.6745938000367483 Test: 0.5975048449612403\n"
     ]
    }
   ],
   "source": [
    "regs = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]\n",
    "ests = [2000, 3000, 4000, 5000]\n",
    "f_scores = []\n",
    "\n",
    "for el1 in ests:\n",
    "    print('***************************')\n",
    "    print('Depth: ',el1)\n",
    "    print('***************************')\n",
    "    for el2 in regs:\n",
    "\n",
    "        tune_reg_lgbm = LGBMClassifier(boosting_type = 'goss',\n",
    "                                learning_rate = 0.003,\n",
    "                                n_estimators = el1,\n",
    "                                objective = 'binary',\n",
    "                                num_leaves = 40,\n",
    "                                max_depth = -1,\n",
    "                                is_unbalance = True,\n",
    "                                reg_lambda = 4*el2\n",
    "                                )\n",
    "\n",
    "        tune_reg_lgbm.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = tune_reg_lgbm.predict(X_train)\n",
    "        y_test_pred = tune_reg_lgbm.predict(X_test)\n",
    "\n",
    "        train_f = f1_score(y_train, y_train_pred)\n",
    "        test_f = f1_score(y_test, y_test_pred)\n",
    "\n",
    "        f_scores.append([el, train_f, test_f])\n",
    "        print(4*el2,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1250b4",
   "metadata": {},
   "source": [
    "#### Tuning the value of $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef737c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 - Train: 0.6481940144478844 Test: 0.5996420047732697\n",
      "0.25 - Train: 0.6477586518361764 Test: 0.6005013129625209\n",
      "0.5 - Train: 0.6467374497474486 Test: 0.5980784149907501\n",
      "0.75 - Train: 0.6474110784161892 Test: 0.5999880718077175\n",
      "1.0 - Train: 0.6465746355308992 Test: 0.5987716892254487\n",
      "1.25 - Train: 0.6475762969842376 Test: 0.5989158277238339\n",
      "1.5 - Train: 0.647758887171561 Test: 0.599165673420739\n",
      "1.75 - Train: 0.6467433345366407 Test: 0.5977903851896088\n",
      "2.0 - Train: 0.6468056593562354 Test: 0.6005966587112171\n",
      "2.25 - Train: 0.6477703556598665 Test: 0.5982783357245337\n",
      "2.5 - Train: 0.6468981863149218 Test: 0.5985331822789339\n",
      "2.75 - Train: 0.6467538497252959 Test: 0.5996066980513676\n",
      "3.0 - Train: 0.6458097103391403 Test: 0.5999166120674251\n",
      "3.25 - Train: 0.6468738724808 Test: 0.598343561937675\n",
      "3.5 - Train: 0.6483018089986085 Test: 0.5993909356899744\n",
      "3.75 - Train: 0.6475061219229281 Test: 0.5994631673128541\n",
      "4.0 - Train: 0.6463512016691997 Test: 0.6001906123421491\n"
     ]
    }
   ],
   "source": [
    "regs = [0.00, 0.25, 0.50, 0.75, 1.00, 1.25, 1.50, 1.75, 2.00, 2.25, 2.50, 2.75, 3.00, 3.25, 3.50, 3.75, 4.00]\n",
    "\n",
    "for el in regs:\n",
    "\n",
    "    tune_reg_lgbm = LGBMClassifier(boosting_type = 'goss',\n",
    "                            learning_rate = 0.003,\n",
    "                            n_estimators = 3000,\n",
    "                            objective = 'binary',\n",
    "                            num_leaves = 40,\n",
    "                            max_depth = -1,\n",
    "                            is_unbalance = True,\n",
    "                            reg_lambda = el\n",
    "                            )\n",
    "\n",
    "    tune_reg_lgbm.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = tune_reg_lgbm.predict(X_train)\n",
    "    y_test_pred = tune_reg_lgbm.predict(X_test)\n",
    "\n",
    "    train_f = f1_score(y_train, y_train_pred)\n",
    "    test_f = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    f_scores.append([el, train_f, test_f])\n",
    "    print(el,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a94d8de",
   "metadata": {},
   "source": [
    "As a summary we keep **num_leaves = 40**, **num_estimators = 3000** and **$\\lambda=3.0$** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26e422f",
   "metadata": {},
   "source": [
    "#### Attemping to set colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f07a1df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 - Train: 0.6449254845435125 Test: 0.5987132133921125\n",
      "0.775 - Train: 0.6449771102309552 Test: 0.5997855355653521\n",
      "0.8 - Train: 0.6460334217370034 Test: 0.5986783354170387\n",
      "0.825 - Train: 0.6455748339597385 Test: 0.5991546109424303\n",
      "0.85 - Train: 0.6460737840065952 Test: 0.5980082294710477\n",
      "0.875 - Train: 0.6460129171705735 Test: 0.5995346894947206\n",
      "0.9 - Train: 0.6458392355834855 Test: 0.6013960980848398\n",
      "0.925 - Train: 0.6464235081840444 Test: 0.5983405957142005\n",
      "0.95 - Train: 0.6465286361763495 Test: 0.5985697258641238\n",
      "0.975 - Train: 0.6460610435141266 Test: 0.5987709563868504\n",
      "1.0 - Train: 0.6458097103391403 Test: 0.5999166120674251\n"
     ]
    }
   ],
   "source": [
    "sam = [0.750, 0.775, 0.800, 0.825, 0.850, 0.875, 0.900, 0.925, 0.950, 0.975, 1.000]\n",
    "f_scores = []\n",
    "\n",
    "for el in sam:\n",
    "    \n",
    "    tune_est_lgbm = LGBMClassifier(boosting_type = 'goss',\n",
    "                                learning_rate = 0.003,\n",
    "                                n_estimators = 3000,\n",
    "                                objective = 'binary',\n",
    "                                num_leaves = 40,\n",
    "                                max_depth = -1,\n",
    "                                is_unbalance = True,\n",
    "                                reg_lambda = 3,\n",
    "                                colsample_bytree = el\n",
    "                                )\n",
    "\n",
    "    tune_est_lgbm.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = tune_est_lgbm.predict(X_train)\n",
    "    y_test_pred = tune_est_lgbm.predict(X_test)\n",
    "\n",
    "    train_f = f1_score(y_train, y_train_pred)\n",
    "    test_f = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    f_scores.append([el, train_f, test_f])\n",
    "    print(el,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401f5e5b",
   "metadata": {},
   "source": [
    "We set colsample_bytree to be **0.90**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e668f984",
   "metadata": {},
   "source": [
    "#### Regularising using min_split_gain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccca8c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 - Train: 0.6589583387343478 Test: 0.5992576628352491\n",
      "0.05 - Train: 0.6596511236100671 Test: 0.597892467967908\n",
      "0.1 - Train: 0.659169819142872 Test: 0.5974492545356566\n",
      "0.15 - Train: 0.6582908064140094 Test: 0.5988734419942474\n",
      "0.2 - Train: 0.6591480646081253 Test: 0.5985156811108452\n",
      "0.25 - Train: 0.6587188704129923 Test: 0.5979875419262097\n",
      "0.3 - Train: 0.6587936705254707 Test: 0.6002395209580839\n",
      "0.35 - Train: 0.6589490586072048 Test: 0.5986964061472225\n",
      "0.4 - Train: 0.6599497526483463 Test: 0.59962845328699\n",
      "0.45 - Train: 0.65943870934274 Test: 0.5995807127882601\n",
      "0.5 - Train: 0.6592462207496377 Test: 0.5978839141610378\n",
      "0.55 - Train: 0.6592893979837768 Test: 0.5984327331458994\n",
      "0.6 - Train: 0.6595942868971227 Test: 0.5992348158775707\n",
      "0.65 - Train: 0.659365128683134 Test: 0.598660607510165\n",
      "0.7 - Train: 0.6589861751152074 Test: 0.6001677450275581\n"
     ]
    }
   ],
   "source": [
    "gain = [0.00, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70]\n",
    "f_scores = []\n",
    "\n",
    "for el in gain:\n",
    "    \n",
    "    tune_est_lgbm = LGBMClassifier(boosting_type = 'goss',\n",
    "                                learning_rate = 0.003,\n",
    "                                n_estimators = 3000,\n",
    "                                objective = 'binary',\n",
    "                                num_leaves = 40,\n",
    "                                max_depth = -1,\n",
    "                                is_unbalance = True,\n",
    "                                reg_lambda = 3,\n",
    "                                colsample_bytree = 0.9,\n",
    "                                min_split_gain = el\n",
    "                                )\n",
    "\n",
    "    tune_est_lgbm.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = tune_est_lgbm.predict(X_train)\n",
    "    y_test_pred = tune_est_lgbm.predict(X_test)\n",
    "\n",
    "    train_f = f1_score(y_train, y_train_pred)\n",
    "    test_f = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    f_scores.append([el, train_f, test_f])\n",
    "    print(el,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795c7cdf",
   "metadata": {},
   "source": [
    "#### L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ad038ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 - Train: 0.6458392355834855 Test: 0.6013960980848398\n",
      "0.5 - Train: 0.6475454194047159 Test: 0.5988902810094863\n",
      "1.0 - Train: 0.645950890211538 Test: 0.5987359885523492\n",
      "1.5 - Train: 0.6462323734886959 Test: 0.5997021149836163\n",
      "2.0 - Train: 0.6467272399680831 Test: 0.6002624358821425\n",
      "2.5 - Train: 0.6453208315087194 Test: 0.5986142635288496\n",
      "3.0 - Train: 0.6456810460207969 Test: 0.5996308864678217\n",
      "3.5 - Train: 0.6460778258184066 Test: 0.5987845567206864\n",
      "4.0 - Train: 0.6455917967743598 Test: 0.5990921036913153\n",
      "4.5 - Train: 0.6463210487007134 Test: 0.5982956915559263\n",
      "5.0 - Train: 0.6463486833637931 Test: 0.5974955277280858\n",
      "5.5 - Train: 0.646300347445631 Test: 0.5980550086510351\n",
      "6.0 - Train: 0.6451230816767948 Test: 0.5985584082921307\n"
     ]
    }
   ],
   "source": [
    "alph = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0]\n",
    "f_scores = []\n",
    "\n",
    "for el in alph:\n",
    "    \n",
    "    tune_est_lgbm = LGBMClassifier(boosting_type = 'goss',\n",
    "                                learning_rate = 0.003,\n",
    "                                n_estimators = 3000,\n",
    "                                objective = 'binary',\n",
    "                                num_leaves = 40,\n",
    "                                max_depth = -1,\n",
    "                                is_unbalance = True,\n",
    "                                reg_lambda = 3,\n",
    "                                reg_alpha = el,\n",
    "                                colsample_bytree = 0.9,\n",
    "                                min_split_gain = 0.0,\n",
    "                                )\n",
    "\n",
    "    tune_est_lgbm.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = tune_est_lgbm.predict(X_train)\n",
    "    y_test_pred = tune_est_lgbm.predict(X_test)\n",
    "\n",
    "    train_f = f1_score(y_train, y_train_pred)\n",
    "    test_f = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    f_scores.append([el, train_f, test_f])\n",
    "    print(el,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1ffc49",
   "metadata": {},
   "source": [
    "Range of values between 1.5 and 2.5 for L1 regularisation usually gives best results. Let us now refine further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7646c00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5 - Train: 0.6457382922240263 Test: 0.5987344794651385\n",
      "1.6 - Train: 0.6465994897301754 Test: 0.5990234607597952\n",
      "1.7 - Train: 0.6467784733493057 Test: 0.5983069035411946\n",
      "1.8 - Train: 0.6457517013817282 Test: 0.5971128608923884\n",
      "1.9 - Train: 0.6453421099997428 Test: 0.5997851515874911\n",
      "2.0 - Train: 0.6461894953656026 Test: 0.5982132221560453\n",
      "2.1 - Train: 0.646553055655666 Test: 0.5987617573520657\n",
      "2.2 - Train: 0.6459422566770546 Test: 0.5984862029918351\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-97161c9ec2d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m                                 )\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mtune_est_lgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtune_est_lgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    965\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m         super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n\u001b[0m\u001b[0;32m    968\u001b[0m                     \u001b[0meval_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_sample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m                     \u001b[0meval_class_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_class_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_init_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    746\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m    749\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    290\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3019\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3020\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot update due to null objective function.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3021\u001b[1;33m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[0;32m   3022\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alph = [1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4, 2.5]\n",
    "f_scores = []\n",
    "\n",
    "for el in alph:\n",
    "    \n",
    "    tune_est_lgbm = LGBMClassifier(boosting_type = 'goss',\n",
    "                                learning_rate = 0.003,\n",
    "                                n_estimators = 3000,\n",
    "                                objective = 'binary',\n",
    "                                num_leaves = 40,\n",
    "                                max_depth = -1,\n",
    "                                is_unbalance = True,\n",
    "                                reg_lambda = 3,\n",
    "                                reg_alpha = el,\n",
    "                                colsample_bytree = 0.9,\n",
    "                                min_split_gain = 0.0,\n",
    "                                )\n",
    "\n",
    "    tune_est_lgbm.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = tune_est_lgbm.predict(X_train)\n",
    "    y_test_pred = tune_est_lgbm.predict(X_test)\n",
    "\n",
    "    train_f = f1_score(y_train, y_train_pred)\n",
    "    test_f = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    f_scores.append([el, train_f, test_f])\n",
    "    print(el,\"- Train:\", train_f, \"Test:\", test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e5f7c5",
   "metadata": {},
   "source": [
    "We use L1 regularization **$\\alpha = 2.5$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a686f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990e887d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5b91f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6458392355834855\n",
      "0.6013960980848398\n"
     ]
    }
   ],
   "source": [
    "tune_lgbm = LGBMClassifier(boosting_type = 'goss',\n",
    "                           learning_rate = 0.003,\n",
    "                           n_estimators = 3000,\n",
    "                           objective = 'binary',\n",
    "                           num_leaves = 40,\n",
    "                           max_depth = -1,\n",
    "                           is_unbalance = True,\n",
    "                           reg_lambda = 3,\n",
    "                           reg_alpha = 0,\n",
    "                           colsample_bytree = 0.9,\n",
    "                           min_split_gain = 0.0,\n",
    "                           )\n",
    "\n",
    "tune_lgbm.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = tune_lgbm.predict(X_train)\n",
    "y_test_pred = tune_lgbm.predict(X_test)\n",
    "\n",
    "train_f = f1_score(y_train, y_train_pred)\n",
    "test_f = f1_score(y_test, y_test_pred)\n",
    "\n",
    "f_scores.append([el, train_f, test_f])\n",
    "print(f1_score(y_train_pred, y_train))\n",
    "print(f1_score(y_test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538070bb",
   "metadata": {},
   "source": [
    "# Random Forests Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c5bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de33d32c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6693f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a1cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba41756b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcc2ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e313354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5bdcdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5f9d098",
   "metadata": {},
   "source": [
    "## Combining LightGBM and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9cc2c93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8409279830726214\n",
      "0.5959990802483329\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(learning_rate = 0.01,  \n",
    "                      colsample_bytree = 0.25,\n",
    "                      subsample = 0.50,\n",
    "                      objective = 'binary:logistic', \n",
    "                      n_estimators = 3000,\n",
    "                      max_depth = 14, \n",
    "                      scale_pos_weight = 5,\n",
    "                      gamma = 4,\n",
    "                      reg_lambda = 8,\n",
    "                      verbosity = 2,\n",
    "                      tree_method = 'gpu_hist')\n",
    "\n",
    "xgb1.fit(X_train, y_train)\n",
    "y_pred01 = xgb1.predict(X_train)\n",
    "y_pred11 = xgb1.predict(X_test)\n",
    "print(f1_score(y_pred01, y_train))\n",
    "print(f1_score(y_pred11, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e9a79d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6458392355834855\n",
      "0.6013960980848398\n"
     ]
    }
   ],
   "source": [
    "lgbm1 = LGBMClassifier(boosting_type = 'goss',\n",
    "                       learning_rate = 0.003,\n",
    "                       n_estimators = 3000,\n",
    "                       objective = 'binary',\n",
    "                       num_leaves = 40,\n",
    "                       max_depth = -1,\n",
    "                       is_unbalance = True,\n",
    "                       reg_lambda = 3,\n",
    "                       reg_alpha = 0,\n",
    "                       colsample_bytree = 0.9,\n",
    "                       min_split_gain = 0.0,\n",
    "                       )\n",
    "\n",
    "lgbm1.fit(X_train, y_train)\n",
    "y_pred02 = lgbm1.predict(X_train)\n",
    "y_pred12 = lgbm1.predict(X_test)\n",
    "print(f1_score(y_pred02, y_train))\n",
    "print(f1_score(y_pred12, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "12ac5791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.662406426876027\n",
      "0.6008909222248977\n"
     ]
    }
   ],
   "source": [
    "lgbm2 = LGBMClassifier(boosting_type = 'goss',\n",
    "                       learning_rate = 0.003,\n",
    "                       n_estimators = 4000,\n",
    "                       objective = 'binary',\n",
    "                       num_leaves = 40,\n",
    "                       max_depth = -1,\n",
    "                       is_unbalance = True,\n",
    "                       reg_lambda = 3,\n",
    "                       reg_alpha = 0,\n",
    "                       colsample_bytree = 0.9,\n",
    "                       min_split_gain = 0.0,\n",
    "                       )\n",
    "\n",
    "lgbm2.fit(X_train, y_train)\n",
    "y_pred03 = lgbm2.predict(X_train)\n",
    "y_pred13 = lgbm2.predict(X_test)\n",
    "print(f1_score(y_pred03, y_train))\n",
    "print(f1_score(y_pred13, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "51710122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6592740368422416\n",
      "0.5997487587485794\n"
     ]
    }
   ],
   "source": [
    "lgbm3 = LGBMClassifier(boosting_type = 'goss',\n",
    "                       learning_rate = 0.003,\n",
    "                       n_estimators = 3000,\n",
    "                       objective = 'binary',\n",
    "                       num_leaves = 50,\n",
    "                       max_depth = -1,\n",
    "                       is_unbalance = True,\n",
    "                       reg_lambda = 4,\n",
    "                       reg_alpha = 0,\n",
    "                       colsample_bytree = 0.9,\n",
    "                       min_split_gain = 0.0,\n",
    "                       )\n",
    "\n",
    "lgbm3.fit(X_train, y_train)\n",
    "y_pred04 = lgbm3.predict(X_train)\n",
    "y_pred14 = lgbm3.predict(X_test)\n",
    "print(f1_score(y_pred04, y_train))\n",
    "print(f1_score(y_pred14, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "28e17950",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred0 = []\n",
    "for i in range(len(y_pred01)):\n",
    "    y_pred0.append((2*y_pred01[i] + y_pred02[i] + y_pred03[i] + y_pred04[i])//3)\n",
    "y_pred0 = np.array(y_pred0)\n",
    "\n",
    "y_pred1 = []\n",
    "for i in range(len(y_pred11)):\n",
    "    y_pred1.append((2*y_pred11[i] + y_pred12[i] + y_pred13[i] + y_pred14[i])//3)\n",
    "y_pred1 = np.array(y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1a822d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.670183043058203, 0.6016832806064585]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f1_score(y_train, y_pred0), f1_score(y_test, y_pred1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ce1856",
   "metadata": {},
   "source": [
    "## Generating the Output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2764ac97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mvar1</th>\n",
       "      <th>mvar2</th>\n",
       "      <th>mvar3</th>\n",
       "      <th>mvar4</th>\n",
       "      <th>mvar5</th>\n",
       "      <th>mvar6</th>\n",
       "      <th>mvar7</th>\n",
       "      <th>mvar8</th>\n",
       "      <th>mvar9</th>\n",
       "      <th>mvar10</th>\n",
       "      <th>...</th>\n",
       "      <th>mvar42</th>\n",
       "      <th>mvar43</th>\n",
       "      <th>mvar44</th>\n",
       "      <th>mvar45</th>\n",
       "      <th>mvar46</th>\n",
       "      <th>mvar47</th>\n",
       "      <th>mvar48</th>\n",
       "      <th>mvar49</th>\n",
       "      <th>mvar50</th>\n",
       "      <th>mvar51</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>578069</th>\n",
       "      <td>1719</td>\n",
       "      <td>0.6174</td>\n",
       "      <td>8.623</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>10729</td>\n",
       "      <td>307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54545</td>\n",
       "      <td>2</td>\n",
       "      <td>0.91837</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>3247</td>\n",
       "      <td>554</td>\n",
       "      <td>4</td>\n",
       "      <td>2216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578070</th>\n",
       "      <td>1795</td>\n",
       "      <td>0.2051</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1685</td>\n",
       "      <td>12711</td>\n",
       "      <td>8913</td>\n",
       "      <td>80519</td>\n",
       "      <td>18099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17241</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>18</td>\n",
       "      <td>554</td>\n",
       "      <td>4</td>\n",
       "      <td>2216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578071</th>\n",
       "      <td>1742</td>\n",
       "      <td>0.5082</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1185</td>\n",
       "      <td>8954</td>\n",
       "      <td>8954</td>\n",
       "      <td>1189</td>\n",
       "      <td>1185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97054</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>11</td>\n",
       "      <td>404</td>\n",
       "      <td>4</td>\n",
       "      <td>1616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578072</th>\n",
       "      <td>1685</td>\n",
       "      <td>0.2595</td>\n",
       "      <td>25.409</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>missing</td>\n",
       "      <td>3354</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>3354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85714</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>32</td>\n",
       "      <td>528</td>\n",
       "      <td>4</td>\n",
       "      <td>2112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578073</th>\n",
       "      <td>1666</td>\n",
       "      <td>1.2678</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>570</td>\n",
       "      <td>570</td>\n",
       "      <td>570</td>\n",
       "      <td>missing</td>\n",
       "      <td>570</td>\n",
       "      <td>...</td>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99617</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>89</td>\n",
       "      <td>419</td>\n",
       "      <td>4</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310027</th>\n",
       "      <td>1736</td>\n",
       "      <td>2.1740</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11</td>\n",
       "      <td>4248</td>\n",
       "      <td>1577</td>\n",
       "      <td>13379</td>\n",
       "      <td>6671</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.43829</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>19</td>\n",
       "      <td>383</td>\n",
       "      <td>4</td>\n",
       "      <td>1532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310028</th>\n",
       "      <td>1724</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.108</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.000</td>\n",
       "      <td>missing</td>\n",
       "      <td>64041</td>\n",
       "      <td>missing</td>\n",
       "      <td>10926</td>\n",
       "      <td>84839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16667</td>\n",
       "      <td>14</td>\n",
       "      <td>0.57931</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "      <td>595</td>\n",
       "      <td>4</td>\n",
       "      <td>2380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310029</th>\n",
       "      <td>1605</td>\n",
       "      <td>0.2901</td>\n",
       "      <td>11.561</td>\n",
       "      <td>0.937</td>\n",
       "      <td>2.976</td>\n",
       "      <td>missing</td>\n",
       "      <td>2277</td>\n",
       "      <td>missing</td>\n",
       "      <td>3964</td>\n",
       "      <td>5709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.42069</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>22</td>\n",
       "      <td>835</td>\n",
       "      <td>4</td>\n",
       "      <td>3340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310030</th>\n",
       "      <td>1780</td>\n",
       "      <td>1.1874</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>6356</td>\n",
       "      <td>4802</td>\n",
       "      <td>3206</td>\n",
       "      <td>18180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06061</td>\n",
       "      <td>9</td>\n",
       "      <td>0.53251</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>9</td>\n",
       "      <td>449</td>\n",
       "      <td>4</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310031</th>\n",
       "      <td>1727</td>\n",
       "      <td>1.9288</td>\n",
       "      <td>1.441</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>25773</td>\n",
       "      <td>2869</td>\n",
       "      <td>132985</td>\n",
       "      <td>71788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07143</td>\n",
       "      <td>12</td>\n",
       "      <td>0.68482</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>89</td>\n",
       "      <td>612</td>\n",
       "      <td>4</td>\n",
       "      <td>2448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47000 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                mvar1   mvar2   mvar3  mvar4  mvar5    mvar6  mvar7    mvar8  \\\n",
       "application_key                                                                \n",
       "578069           1719  0.6174   8.623  0.000  0.000      258    258      258   \n",
       "578070           1795  0.2051   0.000  0.000  0.000     1685  12711     8913   \n",
       "578071           1742  0.5082   0.000  0.000  0.000     1185   8954     8954   \n",
       "578072           1685  0.2595  25.409  0.000  0.000  missing   3354  missing   \n",
       "578073           1666  1.2678   0.000  0.000  0.000      570    570      570   \n",
       "...               ...     ...     ...    ...    ...      ...    ...      ...   \n",
       "310027           1736  2.1740   0.000  0.000  0.000       11   4248     1577   \n",
       "310028           1724  0.0000   1.108  0.768  0.000  missing  64041  missing   \n",
       "310029           1605  0.2901  11.561  0.937  2.976  missing   2277  missing   \n",
       "310030           1780  1.1874   0.000  0.000  0.000        0   6356     4802   \n",
       "310031           1727  1.9288   1.441  0.000  0.000        0  25773     2869   \n",
       "\n",
       "                   mvar9 mvar10  ...   mvar42 mvar43   mvar44  mvar45 mvar46  \\\n",
       "application_key                  ...                                           \n",
       "578069             10729    307  ...  0.54545      2  0.91837       0      0   \n",
       "578070             80519  18099  ...  0.17241      4  0.94563       0      0   \n",
       "578071              1189   1185  ...  0.64706      1  0.97054       0      0   \n",
       "578072           missing   3354  ...  0.85714      1  1.00000      na      0   \n",
       "578073           missing    570  ...  missing      0  0.99617      na      0   \n",
       "...                  ...    ...  ...      ...    ...      ...     ...    ...   \n",
       "310027             13379   6671  ...        0      4  0.43829      na      0   \n",
       "310028             10926  84839  ...  0.16667     14  0.57931       0      0   \n",
       "310029              3964   5709  ...      0.5      4  0.42069      na      0   \n",
       "310030              3206  18180  ...  0.06061      9  0.53251      na      0   \n",
       "310031            132985  71788  ...  0.07143     12  0.68482       0      0   \n",
       "\n",
       "                mvar47 mvar48 mvar49 mvar50 mvar51  \n",
       "application_key                                     \n",
       "578069               C   3247    554      4   2216  \n",
       "578070               C     18    554      4   2216  \n",
       "578071               C     11    404      4   1616  \n",
       "578072               C     32    528      4   2112  \n",
       "578073               L     89    419      4   1676  \n",
       "...                ...    ...    ...    ...    ...  \n",
       "310027               C     19    383      4   1532  \n",
       "310028               C      5    595      4   2380  \n",
       "310029               C     22    835      4   3340  \n",
       "310030               L      9    449      4   1796  \n",
       "310031               C     89    612      4   2448  \n",
       "\n",
       "[47000 rows x 51 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('TestX.csv', index_col = 'application_key',low_memory = False)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "87b5b02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n",
      "1 []\n",
      "2 []\n",
      "3 []\n",
      "4 []\n",
      "5 []\n",
      "6 []\n",
      "7 []\n",
      "8 []\n",
      "9 []\n",
      "10 []\n",
      "11 []\n",
      "12 []\n",
      "13 []\n",
      "14 []\n",
      "15 []\n",
      "16 []\n",
      "17 []\n",
      "18 []\n",
      "19 []\n",
      "20 []\n",
      "21 []\n",
      "22 []\n",
      "23 []\n",
      "24 []\n",
      "25 []\n",
      "26 []\n",
      "27 []\n",
      "28 []\n",
      "29 []\n",
      "30 []\n",
      "31 []\n",
      "32 []\n",
      "33 []\n",
      "34 []\n",
      "35 []\n",
      "36 []\n",
      "37 []\n",
      "38 []\n",
      "39 []\n",
      "40 []\n",
      "41 []\n",
      "42 []\n",
      "43 []\n",
      "44 []\n",
      "45 []\n",
      "46 []\n",
      "47 []\n",
      "48 []\n",
      "49 []\n",
      "50 []\n"
     ]
    }
   ],
   "source": [
    "for i in range(51):\n",
    "    lol = ['na', 'missing', '#VALUE!']\n",
    "    for el in lol:\n",
    "        df_test = df_test.replace(el, np.NaN)\n",
    "    lol = get_non_numeric(list(df_test.iloc[:, i].unique()))\n",
    "\n",
    "df_test = pd.get_dummies(df_test, columns = ['mvar47'], prefix = ['type'])\n",
    "for i in range(51):\n",
    "    lol = get_non_numeric(list(df_test.iloc[:, i].unique()))\n",
    "    print(i,lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "82cebc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 47000 entries, 578069 to 310031\n",
      "Data columns (total 52 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   mvar1   44772 non-null  object \n",
      " 1   mvar2   43673 non-null  float64\n",
      " 2   mvar3   46706 non-null  float64\n",
      " 3   mvar4   46706 non-null  float64\n",
      " 4   mvar5   46706 non-null  float64\n",
      " 5   mvar6   35703 non-null  object \n",
      " 6   mvar7   42521 non-null  object \n",
      " 7   mvar8   35698 non-null  object \n",
      " 8   mvar9   40188 non-null  object \n",
      " 9   mvar10  46705 non-null  object \n",
      " 10  mvar11  20482 non-null  object \n",
      " 11  mvar12  38603 non-null  object \n",
      " 12  mvar13  41193 non-null  object \n",
      " 13  mvar14  47000 non-null  int64  \n",
      " 14  mvar15  28164 non-null  object \n",
      " 15  mvar16  35967 non-null  object \n",
      " 16  mvar17  37568 non-null  object \n",
      " 17  mvar18  38215 non-null  object \n",
      " 18  mvar19  46993 non-null  object \n",
      " 19  mvar20  46705 non-null  object \n",
      " 20  mvar21  33620 non-null  float64\n",
      " 21  mvar22  29632 non-null  float64\n",
      " 22  mvar23  23023 non-null  float64\n",
      " 23  mvar24  35734 non-null  float64\n",
      " 24  mvar25  42402 non-null  object \n",
      " 25  mvar26  40565 non-null  object \n",
      " 26  mvar27  39049 non-null  object \n",
      " 27  mvar28  46705 non-null  object \n",
      " 28  mvar29  46705 non-null  object \n",
      " 29  mvar30  25525 non-null  object \n",
      " 30  mvar31  13857 non-null  object \n",
      " 31  mvar32  42402 non-null  object \n",
      " 32  mvar33  45963 non-null  float64\n",
      " 33  mvar34  46705 non-null  object \n",
      " 34  mvar35  27235 non-null  object \n",
      " 35  mvar36  45270 non-null  object \n",
      " 36  mvar37  42402 non-null  object \n",
      " 37  mvar38  46705 non-null  object \n",
      " 38  mvar39  43372 non-null  object \n",
      " 39  mvar40  10099 non-null  object \n",
      " 40  mvar41  14742 non-null  object \n",
      " 41  mvar42  45833 non-null  object \n",
      " 42  mvar43  46506 non-null  object \n",
      " 43  mvar44  42317 non-null  float64\n",
      " 44  mvar45  20966 non-null  object \n",
      " 45  mvar46  33433 non-null  object \n",
      " 46  mvar48  47000 non-null  int64  \n",
      " 47  mvar49  47000 non-null  int64  \n",
      " 48  mvar50  44772 non-null  object \n",
      " 49  mvar51  44772 non-null  object \n",
      " 50  type_C  47000 non-null  uint8  \n",
      " 51  type_L  47000 non-null  uint8  \n",
      "dtypes: float64(10), int64(3), object(37), uint8(2)\n",
      "memory usage: 18.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "44a7893a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 47000 entries, 578069 to 310031\n",
      "Data columns (total 52 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   mvar1   44772 non-null  object \n",
      " 1   mvar2   43673 non-null  float64\n",
      " 2   mvar3   46706 non-null  float64\n",
      " 3   mvar4   46706 non-null  float64\n",
      " 4   mvar5   46706 non-null  float64\n",
      " 5   mvar6   35703 non-null  object \n",
      " 6   mvar7   42521 non-null  object \n",
      " 7   mvar8   35698 non-null  object \n",
      " 8   mvar9   40188 non-null  object \n",
      " 9   mvar10  46705 non-null  object \n",
      " 10  mvar11  20482 non-null  object \n",
      " 11  mvar12  38603 non-null  object \n",
      " 12  mvar13  41193 non-null  object \n",
      " 13  mvar14  47000 non-null  int64  \n",
      " 14  mvar15  28164 non-null  object \n",
      " 15  mvar16  35967 non-null  object \n",
      " 16  mvar17  37568 non-null  object \n",
      " 17  mvar18  38215 non-null  object \n",
      " 18  mvar19  46993 non-null  object \n",
      " 19  mvar20  46705 non-null  object \n",
      " 20  mvar21  33620 non-null  float64\n",
      " 21  mvar22  29632 non-null  float64\n",
      " 22  mvar23  23023 non-null  float64\n",
      " 23  mvar24  35734 non-null  float64\n",
      " 24  mvar25  42402 non-null  object \n",
      " 25  mvar26  40565 non-null  object \n",
      " 26  mvar27  39049 non-null  object \n",
      " 27  mvar28  46705 non-null  object \n",
      " 28  mvar29  46705 non-null  object \n",
      " 29  mvar30  25525 non-null  object \n",
      " 30  mvar31  13857 non-null  object \n",
      " 31  mvar32  42402 non-null  object \n",
      " 32  mvar33  45963 non-null  float64\n",
      " 33  mvar34  46705 non-null  object \n",
      " 34  mvar35  27235 non-null  object \n",
      " 35  mvar36  45270 non-null  object \n",
      " 36  mvar37  42402 non-null  object \n",
      " 37  mvar38  46705 non-null  object \n",
      " 38  mvar39  43372 non-null  object \n",
      " 39  mvar40  10099 non-null  object \n",
      " 40  mvar41  14742 non-null  object \n",
      " 41  mvar42  45833 non-null  object \n",
      " 42  mvar43  46506 non-null  object \n",
      " 43  mvar44  42317 non-null  float64\n",
      " 44  mvar45  20966 non-null  object \n",
      " 45  mvar46  33433 non-null  object \n",
      " 46  mvar48  47000 non-null  int64  \n",
      " 47  mvar49  47000 non-null  int64  \n",
      " 48  mvar50  44772 non-null  object \n",
      " 49  mvar51  44772 non-null  object \n",
      " 50  type_C  47000 non-null  uint8  \n",
      " 51  type_L  47000 non-null  uint8  \n",
      "dtypes: float64(10), int64(3), object(37), uint8(2)\n",
      "memory usage: 18.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test_imputed = df_test\n",
    "df_test_imputed = pd.DataFrame(df_test_imputed, columns = df_test.columns)\n",
    "df_test_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8822b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_label_cols = list(df_test_imputed.columns)\n",
    "test = np.array(df_test_imputed[non_label_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2d80fd04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1719', 0.6174, 8.623, ..., '2216', 1, 0],\n",
       "       ['1795', 0.2051, 0.0, ..., '2216', 1, 0],\n",
       "       ['1742', 0.5082, 0.0, ..., '1616', 1, 0],\n",
       "       ...,\n",
       "       ['1605', 0.2901, 11.561, ..., '3340', 1, 0],\n",
       "       ['1780', 1.1874, 0.0, ..., '1796', 0, 1],\n",
       "       ['1727', 1.9288, 1.441, ..., '2448', 1, 0]], dtype=object)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "50db7679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='goss', colsample_bytree=0.9, is_unbalance=True,\n",
       "               learning_rate=0.003, n_estimators=3000, num_leaves=50,\n",
       "               objective='binary', reg_alpha=0, reg_lambda=4)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1.fit(X, y)\n",
    "lgbm1.fit(X, y)\n",
    "lgbm2.fit(X, y)\n",
    "lgbm3.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8358cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = xgb1.predict(test)\n",
    "pred2 = lgbm1.predict(test)\n",
    "pred3 = lgbm2.predict(test)\n",
    "pred4 = lgbm3.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0b983d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(len(pred2)):\n",
    "    preds.append((2*pred1[i] + pred2[i] + pred3[i] + pred4[i])//3)\n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2a519b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = pd.DataFrame(df_test.index)['application_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "16640b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_df = pd.DataFrame(preds, columns = ['Predicted'])\n",
    "Y_pred_df.insert(0, 'Application key', column)\n",
    "Y_pred_df.to_csv('winners_pothumukku_17.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "89f4102e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd54fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d3969ed",
   "metadata": {},
   "source": [
    "#### Tuning XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c9a11f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vishnu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:861: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <class 'xgboost.core.DMatrix'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1514\u001b[0m             )\n\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1516\u001b[1;33m             self._Booster = train(\n\u001b[0m\u001b[0;32m   1517\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\u001b[0m in \u001b[0;36mafter_iteration\u001b[1;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Dataset name should not contain `-`'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m             \u001b[0mscore\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_margin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m             \u001b[0msplited\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# into datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;31m# split up `test-error:0.1234`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36meval_set\u001b[1;34m(self, evals, iteration, feval, output_margin)\u001b[0m\n\u001b[0;32m   2000\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfeval\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2001\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2002\u001b[1;33m                 feval_ret = feval(\n\u001b[0m\u001b[0;32m   2003\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdmat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2004\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1111\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[1;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \"\"\"\n\u001b[1;32m-> 1113\u001b[1;33m     return fbeta_score(\n\u001b[0m\u001b[0;32m   1114\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1249\u001b[0m     \"\"\"\n\u001b[0;32m   1250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1251\u001b[1;33m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[0;32m   1252\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1533\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1534\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1336\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"average has to be one of \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1338\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1339\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    326\u001b[0m     \"\"\"\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    326\u001b[0m     \"\"\"\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    262\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'xgboost.core.DMatrix'>"
     ]
    }
   ],
   "source": [
    "tuning_xgb_model = XGBClassifier()\n",
    "\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "eval_metric = [\"auc\"]\n",
    "%time tuning_xgb_model.fit(X_train, y_train, eval_metric = f1_score, eval_set = eval_set, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92b063f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = tuning_xgb_model.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56955b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1aec38904c0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(len(results['validation_0']['auc']))), results['validation_0']['auc'], label = 'train')\n",
    "plt.plot(list(range(len(results['validation_1']['auc']))), results['validation_1']['auc'], label = 'test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1e7c5355",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_xg = XGBClassifier(silent = False, \n",
    "                      learning_rate = 0.01,  \n",
    "                      colsample_bytree = 1,\n",
    "                      subsample = 0.8,\n",
    "                      objective = 'binary:logistic', \n",
    "                      n_estimators = 1000,\n",
    "                      max_depth = 3, \n",
    "                      gamma = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d200d1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:11:44] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[09:12:17] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[09:13:03] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[09:13:56] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[09:15:22] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[09:17:09] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[09:19:15] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "depths = list(range(3, 10))\n",
    "f_scores = []\n",
    "\n",
    "for el in depths:\n",
    "    \n",
    "    test_depth_model = XGBClassifier(learning_rate = 0.3,  \n",
    "                      colsample_bytree = 1,\n",
    "                      subsample = 0.8,\n",
    "                      objective = 'binary:logistic', \n",
    "                      n_estimators = 100,\n",
    "                      max_depth = el, \n",
    "                      gamma = 1)\n",
    "    \n",
    "    test_depth_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = test_depth_model.predict(X_train)\n",
    "    y_test_pred = test_depth_model.predict(X_test)\n",
    "    \n",
    "    train_f = f1_score(y_train, y_train_pred)\n",
    "    test_f = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    f_scores.append([el, train_f, test_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5a6d3137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52022388, 0.50402842],\n",
       "       [0.53730011, 0.50885529],\n",
       "       [0.56206591, 0.51342513],\n",
       "       [0.59723089, 0.5157967 ],\n",
       "       [0.64112463, 0.51613457],\n",
       "       [0.69926563, 0.51618982],\n",
       "       [0.77111622, 0.51649291]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_scores = np.array(f_scores)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677e326d",
   "metadata": {},
   "source": [
    "Pora simaa, ineem venam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a3299365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:25:13] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[09:26:46] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[09:29:11] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[09:32:06] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[09:35:24] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[09:39:06] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "depths = list(range(8, 14))\n",
    "f_scores = []\n",
    "\n",
    "for el in depths:\n",
    "    \n",
    "    test_depth_model = XGBClassifier(silent = False, \n",
    "                      learning_rate = 0.01,  \n",
    "                      colsample_bytree = 1,\n",
    "                      subsample = 0.8,\n",
    "                      objective = 'binary:logistic', \n",
    "                      n_estimators = 1000,\n",
    "                      max_depth = el, \n",
    "                      gamma = 1)\n",
    "    \n",
    "    test_depth_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = test_depth_model.predict(X_train)\n",
    "    y_test_pred = test_depth_model.predict(X_test)\n",
    "    \n",
    "    train_f = f1_score(y_train, y_train_pred)\n",
    "    test_f = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    f_scores.append([train_f, test_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "944a0874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6992656277986744, 0.5161898235394895],\n",
       " [0.7711162175335979, 0.5164929071953512],\n",
       " [0.8384882038165115, 0.5185058843595428],\n",
       " [0.898757120662869, 0.5165868673050614],\n",
       " [0.9424343136640121, 0.5146278870829769],\n",
       " [0.9743307664099743, 0.5173771614449582]]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "888fa4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depths[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee64de5",
   "metadata": {},
   "source": [
    "<b> Max Depth = 10 is a good choice </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "88ca54d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:16:36] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[10:17:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[10:19:34] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[10:21:19] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[10:23:11] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[10:25:10] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[10:27:17] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[10:29:32] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[10:31:58] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[10:34:27] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col_samples = list(np.linspace(0.4, 0.9, 10))\n",
    "f_scores = []\n",
    "\n",
    "for el in col_samples:\n",
    "    \n",
    "    test_depth_model = XGBClassifier(silent = False, \n",
    "                      learning_rate = 0.01,  \n",
    "                      colsample_bytree = el,\n",
    "                      subsample = 0.8,\n",
    "                      objective = 'binary:logistic', \n",
    "                      n_estimators = 1000,\n",
    "                      max_depth = 10, \n",
    "                      gamma = 1)\n",
    "    \n",
    "    test_depth_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = test_depth_model.predict(X_train)\n",
    "    y_test_pred = test_depth_model.predict(X_test)\n",
    "    \n",
    "    train_f = f1_score(y_train, y_train_pred)\n",
    "    test_f = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    f_scores.append([train_f, test_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c5ee691d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.7980210351508442, 0.5140548439783375],\n",
       " [0.8057420221005887, 0.5164230438521067],\n",
       " [0.811027397260274, 0.5170103092783506],\n",
       " [0.8163028253219909, 0.516616573636754],\n",
       " [0.8194250247246189, 0.5178021225607669],\n",
       " [0.8207505368281126, 0.5147817119284978],\n",
       " [0.8251121076233184, 0.5173479903813122],\n",
       " [0.8268376242325566, 0.5125740279804308],\n",
       " [0.832088669617815, 0.516884671283235],\n",
       " [0.8334514528703048, 0.5166881166881166]]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "53646860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6222222222222222"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_samples[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f380b91b",
   "metadata": {},
   "source": [
    "<b> 0.6 for columns used by each tree </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1ad91422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:43:34] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[10:44:21] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[10:46:00] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[10:48:53] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[10:52:47] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[10:57:31] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[11:03:09] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[11:09:54] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator_samples = list(range(500, 4001, 500))\n",
    "f_scores = []\n",
    "\n",
    "for el in estimator_samples:\n",
    "    \n",
    "    test_depth_model = XGBClassifier(silent = False, \n",
    "                      learning_rate = 0.01,  \n",
    "                      colsample_bytree = 0.6,\n",
    "                      subsample = 0.8,\n",
    "                      objective = 'binary:logistic', \n",
    "                      n_estimators = el,\n",
    "                      max_depth = 10, \n",
    "                      gamma = 1)\n",
    "    \n",
    "    test_depth_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = test_depth_model.predict(X_train)\n",
    "    y_test_pred = test_depth_model.predict(X_test)\n",
    "    \n",
    "    train_f = f1_score(y_train, y_train_pred)\n",
    "    test_f = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    f_scores.append([train_f, test_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c55ccd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.7292857142857144, 0.5109287257019439],\n",
       " [0.8185228125213121, 0.5159241136578248],\n",
       " [0.8780007870916962, 0.5160572064742656],\n",
       " [0.9200560117115396, 0.5157318741450068],\n",
       " [0.947568578553616, 0.5172619555025147],\n",
       " [0.9682880451450653, 0.5178753830439223],\n",
       " [0.9805577495595116, 0.5171679304762716],\n",
       " [0.986970585567883, 0.518253765636967]]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8465e6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_samples[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ae51d8",
   "metadata": {},
   "source": [
    "Confused unga bunga, but <b> n_est = 3000 for now </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3246d379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
